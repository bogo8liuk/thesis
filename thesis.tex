\documentclass[10pt,a4paper]{article}
\usepackage[italian]{babel}
\usepackage{newlfont}
\usepackage{listings}
\usepackage{tikz}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{proof}

\lstset{
    language=Haskell,
    basicstyle={\small\ttfamily}
}

\tikzstyle{process} =
    [rectangle, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=white!30]
\tikzstyle{object} =
    [rectangle, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=white!30]
\tikzstyle{arrow} = [thick,->,>=stealth]

\textwidth=450pt\oddsidemargin=0pt

\begin{document}
\begin{titlepage}

\begin{center}

{{\Large {\textsc {Alma Mater Studiorum $\cdot$ Universit\`a di Bologna}}}} \rule[0.1cm]{15.8cm}{0.1mm}

\rule[0.5cm]{15.8cm}{0.6mm}
{\small {\bf SCUOLA DI SCIENZE\\
Corso di Laurea in Nome corso di Laurea }}

\end{center}

\vspace{15mm}
\begin{center}

{\LARGE
    {\bf COMPILATORE PER LINGUAGGIO DI}
}\\
\vspace{3mm}
{\LARGE
    {\bf PROGRAMMAZIONE FUNZIONALE}
}\\
\vspace{3mm}
{\LARGE
    {\bf SPERIMENTALE}
}\\

\end{center}

\vspace{40mm}
\par
\noindent
\begin{minipage}[t]{0.47\textwidth}

{\large
    {\bf Relatore:\\
        Chiar.mo Prof.\\
        CLAUDIO SACERDOTI COEN
    }
}

\end{minipage}

\hfill
\begin{minipage}[t] {0.47\textwidth}\raggedleft
{\large
    {\bf Presentata da:\\
        LUCA BORGHI
    }
}

\end{minipage}

\vspace{20mm}
\begin{center}

{\large
    {\bf Sessione\\
        III sessione
        2021-2022
    }
}%2018-2019

\end{center}

\end{titlepage}

\textwidth=450pt\oddsidemargin=0pt

\section{Introduzione}

%TODO: dove viene descritto il problema, la subsection può essere rimossa
\subsection{Il linguaggio}

\subsection{Haskell come modello}
Il compilatore è stato sviluppato mediante il linguaggio \textit{Haskell}, anch'esso linguaggio di programmazione funzionale.
Inoltre, il linguaggio target di langgg è \textit{Core}, un formalismo fortemente basato su \textit{System F}, una
variante tipata del lambda-calcolo che introduce un meccanismo di quantificazione universale sui tipi. Core, inoltre,
viene utilizzato da GHC (compilatore Haskell) come rappresentazione intermedia di Haskell. All'interno di questo
contesto, GHC espone delle API che permettono al cliente di utilizzare le funzionalità del compilatore (cfr. [2]); è quindi
possibile creare e manipolare programmi Core mediante le API, le quali sono state scritte in Haskell. Per quest'ultimo
motivo, Haskell è stato scelto come linguaggio di implementazione del compilatore di langgg, tuttavia, nel contesto
del progetto, Haskell ha anche un altro importante ruolo: alcune delle sue funzionalità sono state, direttamente
o indirettamente, fonte di ispirazione per il design di langgg. Nel prossimo paragrafo vengono presentate le principali
caratteristiche di langgg ed è possibile ritrovare la maggior parte di esse anche in Haskell. Un altro linguaggio
che è stato fonte di ispirazione, ma con minore impatto, è \textit{OCaml}, linguaggio multi-paradigma (funzionale non
puro), soprattutto per la sintassi di langgg e per il costrutto delle polymorphic variants (cfr. paragrafo sugli
sviluppi futuri).

\subsection{Caratteristiche del linguaggio}
Tra le principali caratteristiche del linguaggio vi sono:
\begin{description}
\item[Linguaggio funzionale puro] Come Haskell, langgg è un linguaggio funzionale puro. La nozione di linguaggio
di programmazione \textit{funzionale} è piuttosto lasca e non vi è una vera e propria definizione formale,
tant'è che il termine viene spesso utilizzato (e, talvolta, abusato) per indicare un linguaggio avente alcune
particolari specifiche attribuibili al paradigma di programmazione funzionale. langgg può essere quindi considerato
funzionale poiché, semplicemente, ha numerose caratteristiche proprie del paradigma funzionale, quali: tipi di dati
algebrici, pattern matching, funzioni di ordine superiore, immutabilità, polimorfismo parametrico etc.. Per quanto
riguarda la nozione di \textit{purità}, nel paradigma funzionale viene fatta spesso la distinzione
tra linguaggi puri e impuri; anche qui, non vi sono vere e proprie definizioni e la questione è spesso oggetto di
controversie. Una proposta di definizione è stata fornita da Amr Sabry in [1]: la purità ha a che fare con il passaggio
dei parametri, in particolare, un linguaggio L può essere
considerato puro se, dato un qualsiasi programma p scritto in L, le funzioni di p sono dei "\textit{mapping}" puri
dai valori in input ai valori in output, indipendentemente dal tipo di passaggio dei parametri.
\item[Type-system statico con type-inference] langgg è un linguaggio con type-system statico, inoltre, la fase di
type-checking garantisce la proprietà di type-safety. Il linguaggio permette anche di omettere le indicazioni di
tipo (type-hinting) nella definizione di simboli; in caso non vi sia type-hinting per la definizione di un simbolo,
il compilatore inferirà il tipo "più generale possibile" per il simbolo.
\item["Everything is an expression"] tutti i costrutti all'interno di langgg possono essere considerati espressioni
prive di side-effects; non vi sono costrutti di controllo o costrutti che modificano variabili di stato esterne
al contesto locale. I costrutti principali sono:
    \begin{enumerate}
    \item definizioni di: tipi, variabili, proprietà (che corrispondono alle type-classes di Haskell), istanze di
    proprietà, alias di tipi, firme di simboli; le definizioni di simboli hanno le seguenti grammatiche:
    \begin{lstlisting}
      S :=
          let var args = E

     MS :=
          let var MPM
    \end{lstlisting}
    \item espressioni date dalla seguente grammatica:
    \begin{lstlisting}
      E :=
          var
          datacon
          literal
          E E
          lam args -> E
          lam MPM
          S in E
          MS in E
          match E with PM

     PM :=
          ME -> E | ... | ME -> E

    MPM :=
          | ME ... ME = E | ... | ME ... ME = E

     ME :=
          var
          _
          literal
          datacon ME ... ME
          
    \end{lstlisting}
    \item un costrutto, valutato a compile-time (cfr. parsing degli operatori), per definire una "categoria" di
    operatori. Le categorie di operatori hanno degli identificatori per poterle nominare, inoltre definiscono le
    seguenti proprietà:
        \begin{enumerate}
        \item una lista di operatori appartenenti alla proprietà. Sono compresi gli identificatori di variabili (gli
        operatori stessi sono identificatori di variabili) che possono essere utilizzati con la sintassi degli operatori;
        \item una lista di categorie di operatori i quali avranno meno precedenza degli operatori della categoria
        corrente;
        \item una lista di categorie di operatori i quali avranno più precedenza degli operatori della categoria
        corrente;
        \item la fissità degli operatori.
        \end{enumerate}
    \end{enumerate}
\item[Tipi di dati algebrici] langgg supporta anche i tipi di dati algebrici (che sono l'unico modo per definire nuovi
tipi). Con essi, vi è anche la nozione di \textit{data constructor}, ovvero un costrutto dotato di tipo che può essere
accompagnato da dati. Per eseguire operazioni con i tipi di dati algebrici vi è il costrutto del pattern matching
(cfr. grammatica delle espressioni) che permette di destrutturare un data constructor dai suoi dati associati.
\item[Polimorfismo parametrico] il sistema di tipi del linguaggio supporta le variabili di tipo. Questo tipo di
polimorfismo permette di avere singoli algoritmi per una moltitudine di tipi.
\item[Kind] Il linguaggio permette la manipolazione di \textit{funzioni di tipi}, introducendo la nozione di
\textit{kind} (cfr. sezione sul sistema di tipi). Quindi, data la seguente definizione di tipo:
\begin{lstlisting}
type M a b = DataCon1 a | DataCon2 b | DataCon3 a Char
\end{lstlisting}
dove \textit{a} e \textit{b} sono variabili di tipo, è possibile, ad esempio, avere tipi della forma:
\begin{lstlisting}
M Int Char
M a b
M String
M x
M
\end{lstlisting}
\`E possibile altresì avere un tipo della forma:
\begin{lstlisting}
m Int
\end{lstlisting}
dove \textit{m} è una variabile di tipo a cui viene applicata il tipo \textit{Int}.
\item[Polimorfismo ad hoc] attraverso il meccanismo delle type-classes (all'interno del linguaggio vengono chiamate
proprietà), è possibile creare funzioni polimorfe che possono essere applicate ad argomenti di tipi differenti e, a
seconda dei tipi degli argomenti, viene "selezionata" la giusta implementazione. Ogni proprietà può avere uno, ma anche
più tipi associati; inoltre, i tipi associati alle proprietà possono essere anche variabili di tipo.

\end{description}

\section{Il compilatore}

\subsection{La struttura}
\begin{tikzpicture}[node distance=2cm]
\node (src) [object] {Codice sorgente};
\node (parser) [process, below of=src] {Parser};
\draw [arrow] (src) -- (parser);
\node (checker) [process, below of=parser] {Checker della correttezza};
\draw [arrow] (parser) -- (checker);
\node (typedBuilder) [process, below of=checker] {Costruzione dei token tipati};
\draw [arrow] (checker) -- (typedBuilder);
\node (prepare) [process, below of=typedBuilder] {Preparazione alla type inference};
\draw [arrow] (typedBuilder) -- (prepare);
\node (typeInf) [process, below of=prepare] {Type inference - type checking};
\draw [arrow] (prepare) -- (typeInf);
\node (CoreGen) [process, below of=typeInf] {Generazione codice Core};
\draw [arrow] (typeInf) -- (CoreGen);
\node (backend) [process, below of=CoreGen] {Backend};
\draw [arrow] (CoreGen) -- (backend);
\node (exe) [process, below of=backend] {Eseguibile};
\draw [arrow] (backend) -- (exe);
\node (desugar) [process, right of=prepare, xshift=7cm] {Desugaring};
\draw [arrow] (desugar) -- (checker);
\draw [arrow] (desugar) -- (typedBuilder);
\draw [arrow] (desugar) -- (prepare);
\draw [arrow] (desugar) -- (typeInf);
\draw [arrow] (desugar) -- (CoreGen);
\end{tikzpicture}
\newline

La struttura del compilatore è sequenziale, con eccezione fatta per la fase di \textit{desugaring}. Quest'ultima si
occupa di rimuovere il cosiddetto "zucchero sintattico" dalle strutture dati - che mantengono le informazioni del
programma - che, durante le varie fasi di compilazione, possono subire semplificazioni. Talvolta, alcune semplificazioni
vengono posticipate il più possibile per permettere al compilatore di restituire in output messaggi d'errore comprensibili
per l'utente. Un esempio ne è la trasformazione che subiscono le strutture dati che rappresentano il costrutto del
pattern matching. Il modulo che si occupa del desugaring si presenta come una libreria che espone delle API che agiscono
sulle strutture dati del compilatore. \`E compito del compilatore fare le chiamate al modulo di desugaring. Di seguito,
vi è una più ampia e precisa descrizione delle singole fasi di compilazione, con enfasi particolare sugli algoritmi
più interessanti utilizzati per risolvere i singoli sottoproblemi e su come le varie fasi interagiscono tra loro.

\section{L'albero di sintassi astratta}
Nella prima parte del compilatore viene eseguito il parsing del sorgente.
Questa operazione produce quindi l'albero di sintassi astratta (AST). Il codice che gestisce i "token" dell'AST è
all'interno del modulo \texttt{Compiler.Ast.Tree}; l'entry point dell'albero è dato dal token \texttt{Program}, il
quale, come nodi figli, ha delle \texttt{Declaration} che rappresentano i vari costrutti del linguaggio.

\begin{lstlisting}
newtype Program a = Program [Declaration a]

data Declaration a =
      ADT (AlgebraicDataType a)
    | AliasADT (AliasAlgebraicDataType a)
    | Intf (Interface a)
    | Ins (Instance a)
    | Sig (Signature a)
    | Let (SymbolDeclaration a)
    | LetMulti (MultiSymbolDeclaration a)
\end{lstlisting}

Di seguito vi è lo schema della prima parte del compilatore: \newline

\begin{tikzpicture}[node distance=2cm]
\node (src) [object] {Codice sorgente};
\node (rawast) [object, below of=src] {Albero di sintassi astratta};
\draw [arrow] (src) -- node[anchor=west] {Parser} (rawast);
\node (rawastBuiltin) [object, below of=rawast] {Albero di sintassi astratta};
\draw [arrow] (rawast) -- node[anchor=west] {Aggiunta token built-in} (rawastBuiltin);
\node (rawastNames) [object, below of=rawastBuiltin] {Albero di sintassi astratta};
\draw [arrow] (rawastBuiltin) -- node[anchor=west] {Check esistenza dei nomi} (rawastNames);
\node (rawastArgs) [object, below of=rawastNames] {Albero di sintassi astratta};
\draw [arrow] (rawastNames) -- node[anchor=west] {Check numero degli argomenti} (rawastArgs);
\node (rawastAlias) [object, below of=rawastArgs] {Albero di sintassi astratta};
\draw [arrow] (rawastArgs) -- node[anchor=west] {Sostituzione degli alias di tipo} (rawastAlias);
\node (desugar) [object, right of=rawastAlias, xshift=7cm] {Desugaring};
\draw [arrow] (desugar) -- (rawastAlias);
\end{tikzpicture}

\subsection{Il parser}
Il parser è la prima componente del compilatore (dopo la lettura del sorgente). \`E stato scritto mediante la libreria
open-source \texttt{Parsec} [4], la quale si basa sul concetto di parser combinator monadico. Il codice risiede nel
modulo \texttt{Compiler.Syntax} ed ha una struttura gerarchica: parte definendo i combinators di "pezzi" primitivi dei
token dell'AST (\texttt{Compiler.Syntax.Lib.SimpleParser}), dopodiché, nel modulo \texttt{Compiler.Syntax.Grammar} vi
è la generazione vera e propria dei token dell'AST e, infine, vi è l'entry point del parser, ovvero
\texttt{Compiler.Syntax.Parser}. \`E bene notare che all'interno del modulo \texttt{Compiler.Syntax.Lib.SimpleParser}
non sono visibili le API dell'AST, in quanto esso si occupa soltanto del parsing dei costrutti del linguaggio e non
della generazione dei token.

\subsubsection{Parsing degli operatori}
langgg permette di definire operatori che vengono trattati come simboli di variabili (funzioni). In questo contesto,
il linguaggio espone all'utente un costrutto particolare che permettere di definire le proprietà degli eventuali
operatori. Questo costrutto viene valutato durante il parsing e definisce una categoria di operatori, ecco un esempio:

\begin{lstlisting}
OPERATORS_CATEGORY {#
    name : Application ;
    operators : |>, <|, `applyTo ;
    lesser than : Comparison, Numeric ;
    greater than : Functor ;
    fixity : InfixLeft ;
#}
\end{lstlisting}

Il primo "campo" è il nome della categoria ed è utile per poter identificare la categoria, infatti, il terzo e il
quarto campo definiscono rispetto a quali categorie gli attuali operatori hanno precedenza. Il secondo campo definisce
l'insieme di operatori che fanno parte della categoria. Infine, l'ultimo campo è una costante e definisce la fissità
degli operatori: infissa senza associazione, infissa con associazione a sinistra, infissa con associazione a destra,
postfissa o prefissa. La versione infissa è solo per gli operatori binari, mentre postfissa e prefissa solo per gli
operatori unari. Si può notare che nella lista di operatori vi è anche un simbolo di variabile preceduto dal simbolo
di backtick; questo è possibile, in quanto langgg permette di utilizzare i simboli di variabili come operatori
facendoli precedere dal carattere backtick. La valutazione di questo costrutto è interamente integrata nel parser ed
è obbligatorio per l'utente definire le categorie degli operatori all'inizio del sorgente. La libreria \texttt{Parsec}
offre delle API anche per il parsing degli operatori; l'algoritmo di gestione delle categorie si occupa di costruire
una tabella di operatori, implementata semplicemente come una lista di liste, ordinando i gruppi (di categorie) in
base alla loro precedenza. Le informazioni sulle categorie vengono estrapolate dal parsing del costrutto e vengono
passate successivamente all'algoritmo di ordinamento delle categorie. Quest'ultimo si può ridurre all'inserimento
di un elemento in una lista di liste:

\begin{lstlisting}
insert(x, ll):
    match ll with
        [] -> [[x]]
        (l :: lt) ->
            if any x' in l. x' < x        // Condizione d'inserimento (1)
            then
                if areAmbigous(x, ll)
                then fail
                else [x] :: l :: lt
            else if all x' in l. x' == x  // Condizione d'inserimento (2)
            then
                if areAmbigous(x,ll)
                then fail
                else subInsert(x, l) :: lt
            else l :: insert(x, lt)
\end{lstlisting}

L'algoritmo scorre la lista finché non:
\begin{enumerate}
    \item trova una sottolista \textit{l} in cui esiste almeno un elemento minore di \textit{x}; in questo caso, controlla
    eventuali ambiguità delle categorie, poiché l'utente potrebbe aver definito categorie tali che la nozione di
    ordinamento tra loro non è transitiva. La funzione \texttt{areAmbigous} nel pezzo di pseudocodice si occupa
    di eseguire questo controllo. Se non esistono ambiguità tra le categorie, allora viene creata una nuova lista
    singoletto contenente \textit{x} che viene inserita davanti alla sottolista \textit{l}
    \item trova una sottolista \textit{l} in cui tutti gli elementi sono uguali a \textit{x}; in questo caso, \textit{x}
    viene inserito in \textit{l}, eseguendo sempre prima il controllo sulle ambiguità.
\end{enumerate}
In tutti gli altri casi, la corrente sottolista \textit{l} contiene almeno un elemento $ x' $ tale che
$ x' > x $, quindi l'inserimento non può ancora avvenire. Quando la tabella è completa, essa viene passata alla
funzione \texttt{buildExpressionParser} della libreria \texttt{Parsec} che si occupa di costruire il parser per le
espressioni.

\subsection{Check dei nomi}
Dopo la fase di parsing e dell'aggiunta di token built-in del linguaggio (ad esempio, alcuni operatori aritmetici),
viene effettuato il controllo di esistenza di ogni tipo di simbolo: nomi di tipo, nomi di variabili, nomi di proprietà,
etc.. Perciò deve valere la seguente condizione:
    \[ \forall name \in AST. \exists def(name) \]
dove \textit{def} è la funzione che ritorna la definizione di un token dell'AST.
Questo tipo di check è molto importante in quanto fasi successive del compilatore basano le loro computazioni
sull'ipotesi che tutti i simboli sono stati definiti. Il codice risiede nel modulo \texttt{Compiler.Args}.

\subsection{Check degli argomenti}
Il controllo degli argomenti viene effettuato, a differenza del check dei nomi che viene eseguito su ogni tipo di nome,
solo sui nomi di tipo, di alias e di proprietà. In particolare, devono valere le seguenti condizioni:
\[ \forall name \in AST. \]
\begin{enumerate}
    \item:
        \[ isTypeName(name) \Longrightarrow \# args(name) \leq \#args(def(name)) \]
    \item:
        \[ isAliasName(name) \Longrightarrow \#args(name) = \#args(def(name)) \]
    \item:
        \[ isPropertyName(name) \Longrightarrow \#args(name) = \#args(def(name)) \]
\end{enumerate}
dove \textit{isTypeName}, \textit{isAliasName}, \textit{isPropertyName} sono le funzioni che ritornano \textit{true}
se il nome in input è, rispettivamente, un nome di tipo, un nome di alias, un nome di proprietà, \textit{false} altrimenti,
\textit{args} è la funzione che calcola gli argomenti di un token e il simbolo \textit{\#} è la funzione che calcola
la cardinalità di un insieme. La condizione (1) è meno stringente di (2) e di (3),
in quanto l'utente può "manipolare" non solo tipi, ma anche funzioni di tipi,
anche conosciute come \textit{type constructor}. La condizione (2) è fondamentale per la prossima fase del compilatore.
Il codice risiede nel modulo \texttt{Compiler.Args}.

\subsection{Eliminazione degli alias di tipo}
langgg offre un costrutto che permette all'utente di definire alias di tipi. Ecco un esempio:

\begin{lstlisting}
alias CharAnd x = Tuple2 Char x
\end{lstlisting}

Questo tipo di costrutto viene completamente valutato in fase di compilazione: ogni occorrenza di nome di alias viene
trattata come una vera e propria macro, quindi viene sostituita con il tipo associato all'alias. Il modulo di Desugaring
si occupa di questo task (\texttt{Compiler.Desugar.Alias}).
Come si nota nell'esempio, gli alias ammettono argomenti (variabili di tipo) che vengono passati alla funzione di tipo.
Il linguaggio ammette anche alias di alias, tuttavia, ciò può portare a \textit{cicli} di alias, come ad esempio:

\begin{lstlisting}
alias A = B
alias B = C
alias C = A
\end{lstlisting}

Per questo motivo, l'algoritmo di sostituzione degli alias implementa anche la "cycle detection". Inoltre, nella
sostituzione è fondamentale che valga la condizione sugli alias nel check degli argomenti (cfr. check degli argomenti):
    \[ \forall name \in AST. isAliasName(name) \Longrightarrow \#args(name) = \#args(def(name)) \]
Se la sopracitata condizione non fosse vera, non sarebbe possibile effettuare l'unificazione nella kind-inference (cfr.
kind-inference).

\subsection{Eliminazione delle firme di funzioni}
langgg espone un costrutto, detto \textit{signature} (in italiano "firma"), che permette di indicare il tipo di un
binding. Ad esempio:

\begin{lstlisting}
val id : a -> a
\end{lstlisting}

L'esempio appena mostrato indica che la variabile \textit{id} ha tipo $ \forall \alpha. \alpha \mapsto \alpha $. Questo
tipo di costrutto non è nient'altro che "zucchero sintattico" per il type-hinting dei binding. I token dei binding
- \texttt{SymbolDeclaration} e \texttt{MultiSymbolDeclaration} - possono possedere delle informazioni sul type-hinting,
ad esempio, guardando la definizione di \texttt{MultiSymbolDeclaration}:

\begin{lstlisting}
data MultiSymbolDeclaration a =
    MultiSymTok (SymbolName a) (Hint a) (MultiPatternMatch a) a
\end{lstlisting}

si può notare che il costruttore \texttt{MultiSymTok} prenda in input un token \texttt{Hint}. Il task del modulo
\texttt{Desugar.Sigs} è di eliminare dall'AST i costrutti \texttt{Signature} che rappresentano, appunto, le firme delle
variabili e aggiungere la loro informazione sul tipo come type-hinting delle definizioni delle variabili.

\section{Generazione dei token "tipati"}
Dopo la generazione dell'albero di sintassi astratta e alcune fasi di desugaring, questa seconda macro componente del
compilatore si occupa della generazione dei token "tipati". Questi ultimi prendono questa nomea in quanto, a questo
livello, compaiono le nozioni di tipo e di kind del linguaggio.

\begin{tikzpicture}[node distance=2cm]
\node (desast) [object] {AST "dezuccherato"};
\node (desastContsCheck) [object, below of=desast] {AST "dezuccherato"};
\draw [arrow] (desast) -- node[anchor=east] {Check dei constraints} (desastContsCheck);
\node (typesTable) [object, below of=desastContsCheck] {Tabella dei tipi};
\draw [arrow] (desastContsCheck) -- node[anchor=east] {Kind-inference} (typesTable);
\node (consTable) [object, below of=typesTable] {Tabella dei costrutturi};
\draw [arrow] (typesTable) -- node[anchor=east] {Costruzione dei data constructor} (consTable);
\node (contsTable) [object, below of=consTable] {Tabella dei constraints o predicati};
\draw [arrow] (consTable) -- node[anchor=east] {Costruzione dei constraints} (contsTable);
\node (instances) [object, below of=contsTable] {Tabelle di: metodi di proprietà; metodi di istanza; istanze};
\draw [arrow] (contsTable) -- node[anchor=east] {Valutazione delle istanze di proprietà} (instances);
\node (bindings) [object, below of=instances] {Bindings dell'AST pronti per la type-inference};
\draw [arrow] (instances) -- node[anchor=east] {"Preparazione" alla type-inference} (bindings);
\node (tyBindings) [object, below of=bindings] {Bindings tipati};
\draw [arrow] (bindings) -- node[anchor=east] {type-inference} (tyBindings);
\node (desugar) [object, right of=bindings, xshift=6cm] {Desugaring};
\draw [arrow] (desugar) -- (instances);
\draw [arrow] (desugar) -- (bindings);
\draw [arrow] (desugar) -- (tyBindings);
\end{tikzpicture}

\subsection{Approccio a tabelle}
A differenza della prima macro componente del compilatore, dove l'unica struttura dati di primo livello era l'AST, in
questo caso vi sono molteplici strutture dati di primo livello. Innanzitutto, nel modulo \texttt{Compiler.Ast.Typed},
vi sono le definizioni di tutti i token tipati e le operazioni su di essi; proprio in questo modulo compaiono:
\begin{enumerate}
    \item le nozioni che riguardano i tipi del linguaggio:
    \begin{lstlisting}
data LangKind               --kind
data LangVarType a          --variabile di tipo
data LangHigherType a       --mono-tipo
data LangSpecConstraint a   --"constraint" o predicato
data LangQualType a         --mono-tipo qualificato
data LangTypeScheme a       --poli-tipo o schema di tipo
    \end{lstlisting}
    \item i token tipati che costituiscono un programma:
    \begin{lstlisting}
data NotedVar a           --variabili
data NotedVal a           --valori: letterali e data constructor
data NotedMatchExpr a     --espressioni per il pattern match
data NotedExpr a          --expressioni
    \end{lstlisting}
    \item operazioni che riguardano la manipolazione dei tipi quali unificazione, test di specificità, specializzazione,
    instanziazione, generalizzazione. Inoltre, vi sono le funzioni e le strutture dati per gestire il dispatch statico.
\end{enumerate}
Nonostante la presenza di token tipati, non esiste una corrispondente versione tipata dell'AST con un unico entry point,
bensì le informazioni che riguardano un programma vengono memorizzate in "tabelle" (cfr. modulo
\texttt{Compiler.Types.Tables}):
\begin{lstlisting}
newtype TypesTable a          --tabella dei "modelli" di tipi
newtype DataConsTable a       --tabella dei data constructor
newtype ConstraintsTable a    --tabella dei "modelli" di constraints
newtype InstsTable a          --tabella dei bindings delle istanze
newtype PropMethodsTable a    --tabella dei metodi di proprieta'
newtype ImplTable a           --tabella delle istanze
data    TypedProgram a        --tabella dei bindings tipati
\end{lstlisting}
Vedremo nel dettaglio ogni tabella nelle descrizioni delle varie fasi del compilatore. Tuttavia, è necessaria una nota
su \texttt{TypesTable} e \texttt{ConstraintsTable}. Come si legge dai commenti, esse sono tabelle per memorizzare dei
"modelli". Tali modelli sono necessari alla costruzione dei tipi e dei predicati all'interno di un programma. Ad esempio,
date le seguenti definizioni in langgg:
\begin{lstlisting}
type Box a = Boxing a
property Stateful m =
    val getState : m a -> a
;;
\end{lstlisting}
Verranno creati dei token (presenti in \texttt{Compiler.Ast.Typed}) dei tipi:
\begin{lstlisting}
data LangNewType a            --type constructor
data LangNewConstraint a      --constraint constructor
\end{lstlisting}
che rappresenteranno rispettivamente il modello per tipi \texttt{Box} e il modello per constraints \texttt{Stateful} e che
verranno memorizzati nelle suddette tabelle.

Sempre nel modulo \texttt{Compiler.Types.Tables}, viene definito anche il cosiddetto "binding tipato":
\begin{lstlisting}
type BindingSingleton a = (NotedVar a, [NotedVar a], NotedExpr a)
data TypedBinding a =
      TyNonRec (BindingSingleton a)
    | TyRec [BindingSingleton a]
\end{lstlisting}
Osservando l'implementazione di \texttt{TypedBinding}, si nota come esistano due tipi di binding. Il primo è per i binding
non ricorsivi, mentre il secondo è per i binding che sono mutualmente ricorsivi fra loro (cfr. type-inference).

\subsubsection{Confronto con GHC}
Come è stato detto precedentemente, l'approccio del compilatore è quello di costruire tabelle man mano che le informazioni
vengono inferite dall'AST. GHC (the Glasgow Haskell Compiler) utilizza un approccio differente, in quanto non utilizza
alcuna "symbol table", bensì ogni token tipato (di GHC) nella compilazione di un programma Haskell da parte di GHC può
textit{puntare} ad altri token tipati [5]. Si crea così un grafo di strutture dati tipate. Ad esempio, GHC, per gestire
le entità di type constructor e data constructor, utilizza rispettivamente i token \texttt{TyCon} e \texttt{DataCon} (si
ricordi che GHC è scritto in Haskell):
\begin{lstlisting}
data TyCon
data DataCon
\end{lstlisting}
Ogni token di tipo \texttt{TyCon} punterà a una lista di \texttt{DataCon} che, a loro volta, conterranno la referenza
al loro costruttore di tipo. Come puntualizza Edward Y. Zang nell'introduzione dell'articolo [6],
uno svantaggio di questo approccio è che il grafo è immutabile e quindi, per poter
aggiornare i nodi del grafo è necessario ricostruire il grafo da zero. Tuttavia, questo problema è mitigato, in quanto
gli aggiornamenti del grafo sono parecchio rari, inoltre, man mano che GHC ottiene informazioni dal programma Haskell,
accrescerà il grafo senza aggiornare i nodi preesistenti; in questo modo, non vi è alcuna necessità di costruire il
grafo da zero.

\subsection{Il sistema di tipi}
In questo paragrafo, verrà presentato il sistema di tipi di langgg. Come è stato già menzionato in precedenza, il
linguaggio supporta il polimorfismo ad hoc e il polimorfismo parametrico; quest'ultimo viene implementato attraverso
il concetto di variabile di tipo, la quale può essere considerata come un "placeholder" per i tipi.

\subsubsection{Mono-tipo}
Di seguito, viene definito il concetto di \textit{mono-tipo}:
\[ MT \; := \; \alpha \; | \; T \; | \; MT \; MT \; | \; MT \mapsto MT \]
dove $ \alpha $ è una variabile di tipo e $ T $ è un costruttore di tipo. Come si può dedurre dalla definizione stessa,
non si deve confondere
il concetto di mono-tipo con quello di tipo \textit{monomorfo}, infatti i mono-tipi, a differenza dei tipi monomorfi,
ammettono le variabili di tipo. L'ultimo caso è il tipo \textit{funzione}; nella sezione sull'inferenza di tipo verrà
mostrato il motivo per il quale è fondamentale garantire la presenza del tipo funzione all'interno del type-system.
Nel compilatore, la definizione di mono-tipo si trova nel modulo \texttt{Compiler.Ast.Typed}:
\begin{lstlisting}
data LangHigherType a =
      LTy (LangType a)
    | HApp [LangHigherType a] a
\end{lstlisting}
dove \texttt{LangType} rappresenta tutti i tipi che possono essere definiti in langgg. Si noti come vi è un secondo
caso (\texttt{HApp}), il quale rappresenta il tipo funzione. Il costruttore \texttt{HApp} prende in input una lista
di mono-tipi, tuttavia il tipo funzione può avere al massimo due argomenti, perciò il modulo \texttt{Compiler.Ast.Typed}
si occupa internamente di rifiutare qualsiasi valore con costruttore \texttt{HApp} che abbia più di due argomenti.
La causa per la quale non vi è un numero fissato di argomenti è la presenza delle funzioni di tipo, infatti,
in questo modo, è possibile esprimere senza difficoltà, all'interno del compilatore, tipi come:
\begin{itemize}
\item \texttt{(->) a}
\item \texttt{(->)}
\end{itemize}

\subsubsection{Tipi higher-kinded}
langgg permette all'utente di utilizzare \textit{funzioni di tipo} (o \textit{costruttori di tipo}). A questo scopo,
viene introdotta la nozione di \textit{kind}, il quale rappresenta un'informazione aggiuntiva per i tipi. Informalmente,
dato un type-system \textit{TS}, un kind-system \textit{KS} si può vedere come un type-system di livello "superiore"
a \textit{TS}. Ora diamo una definizione più precisa di kind:
\[ K \; := \; \kappa \; | \; * \; | \; K \mapsto K \]
dove $ \kappa $ è una variabile di kind e $ * $ è la costante primitiva di kind (detta anche "tipo"), il quale
rappresenta tutti quei tipi che non hanno bisogno di parametri di tipi. Ecco alcuni esempi:
\begin{itemize}
    \item $ * \mapsto * $ è il kind delle funzioni di tipo unarie;
    \item $ (* \mapsto *) \mapsto * \mapsto * $ è il kind delle funzioni di tipo binarie che prendono in input una
    funzione di tipo unaria e un tipo e ritornano un altro tipo.
    \item $ \kappa_1 \mapsto \kappa_2 $ è il kind delle funzioni unarie che prendono in input una funzione di tipo
    di kind $ \kappa_1 $ e ritorna un'altra funzione di tipo di kind $ \kappa_2 $.
\end{itemize}
Data la presenza di tipi \textit{higher-kinded} all'interno di langgg, è doveroso fare un'ulteriore precisazione che
riguarda i mono-tipi: alla definizione di mono-tipo deve essere aggiunta la condizione sulla correttezza dei kind.
Ad esempio, dato il tipo:
\[ t_1 \mapsto t_2 \]
sapendo che il kind del costruttore di tipo funzione è $ * \mapsto * \mapsto * $, è necessario, affinché il suddetto
kind venga rispettato, che il kind di $ t_1 $ e $ t_2 $ sia $ * $.
%TODO: definizione di kind nel codice

\subsubsection{Subtyping: predicati e tipi qualificati}
La nozione di mono-tipo ammette le variabili di tipo, le quali fungono da placeholder per qualsiasi tipo dello stesso
kind della variabile. Tuttavia, solamente con la nozione di mono-tipo non è possibile fare asserzioni sulle variabili
di tipi, se non, appunto, che sono placeholder adatti a qualsiasi tipo. langgg supporta anche una nozione di sottotipo.
Prendiamo, ad esempio, la seguente variabile di tipo:
\[ \alpha : * \]
la notazione $ : * $ serve, in questo caso, per rendere esplicito il kind della variabile. $ \alpha $ è un placeholder
adatto a tipi quali, ad esempio, \texttt{Int}, \texttt{List b} oppure \texttt{List Char} poiché hanno tutti kind $ * $.
Potrebbe essere "comodo" fare asserzioni su $ \alpha $, ad esempio, si può asserire che $ \alpha $ è un placeholder
valido per tutti quei tipi $ S $ che sono sottotipi di un certo tipo $ T $. Una definizione lasca di sottotipo è la
seguente: se $ S $ è sottotipo di $ T $ (scriviamo $ S \leq T $), allora ogni termine di $ S $ può essere utilizzato
in maniera \textit{safe} in ogni \textit{contesto} in cui un termine di $ T $ è richiesto, dove le definizioni di
\textit{safe} e \textit{contesto} sono dipendenti dal formalismo.
Aggiungiamo una notazione per descrivere questa nozione:
\[ \alpha \leq T . \; \alpha \]
Possiamo quindi "restringere" i possibili tipi adatti a "riempire" il placeholder rappresentato da $ \alpha $. Più in
generale, possiamo considerare $ \alpha \leq T $ come un predicato $ P $ su $ \alpha $. Utilizzeremo, quindi, la seguente
notazione:
\[ P(\alpha) \Rightarrow \alpha \]
Ora abbiamo una sintassi per descrivere \textit{predicati} o \textit{constraint} sulle variabili di tipo. Tale
comportamento si può estendere a qualsiasi forma di tipo, non solo alle variabili di tipo, ma per farlo è necessario
prima definire la sintassi dei predicati. In langgg, un predicato o constraint ha la seguente forma:
\[ C := P \; MT_1 \; ... \; MT_n \]
dove $ P $ è il nome di una proprietà (cfr. polimorfismo ad hoc). Ora possiamo quindi definire un'estensione dei
mono-tipi, in modo che su questi ultimi si possano aggiungere delle ipotesi. Per una definizione più generale possibile,
ammettiamo che su un mono-tipo si possa applicare un numero arbitrario di predicati:
\[ QT := MT \; | \; C \Rightarrow QT \]
Questa appena data è la nozione di \textit{tipo qualificato}. La definizione si trova nel modulo
\texttt{Compiler.Ast.Typed}:
\begin{lstlisting}
data LangQualType a = Qual [LangSpecConstraint a] (LangHigherType a)
\end{lstlisting}

\subsubsection{Schemi di tipi}
Finora abbiamo trattato mono-tipi e tipi qualificati, tuttavia, la sola presenza delle variabili di tipo non è sufficiente
a costruire tipi "polimorfi". Si consideri il seguente esempio:
\[ map : (\alpha \mapsto \beta) \mapsto List \; \alpha \mapsto List \; \beta \]
In questo caso, il tipo della funzione $ map $ non è polimorfo, in quanto le variabili di tipo $ \alpha $ e $ \beta $
rappresentano un tipo fissato non ancora conosciuto. Per ottenere il polimorfismo, è necessario introdurre
dei quantificatori, ad esempio, possiamo rifinire il tipo di $ map $ nel modo seguente:
\[ map : \forall \alpha, \beta . \; (\alpha \mapsto \beta) \mapsto List \; \alpha \mapsto List \; \beta \]
A differenza di prima, in cui $ map $ aveva un tipo prefissato, qui può avere molteplici tipi. Ora diamo la definizione
di \textit{schema di tipo} o \textit{poli-tipo} in langgg:
\[ PT := QT \; | \; \forall \alpha. \; PT \]
Questa definizione lascia spazio alla presenza di \textit{variabili libere}, in quanto non necessariamente tutte le
variabili di tipo che compaiono in un tipo qualificato sono legate a un quantificatore. Le variabili libere vengono
trattate come costanti. Si noti come i quantificatori possono apparire solamente alla testa di un tipo, ad esempio, il
seguente tipo non è accettato in langgg:
\[ \forall \alpha . \; (\forall \alpha . \; \alpha \mapsto \alpha) \mapsto \alpha \]
%TODO: System F
La definizione di schema di tipo in langgg si trova nel modulo \texttt{Compiler.Ast.Typed}:
\begin{lstlisting}
data LangTypeScheme a = Forall [LangVarType a] (LangQualType a)
\end{lstlisting}
La politica sulla sintassi degli schemi di tipi di langgg è omettere il quantificatore $ \forall $. Per questo, ogni qual
volta vi è un costrutto di type-hinting (firme comprese), il tipo viene considerato come uno schema di tipo in cui tutte
le variabili di tipo che compaiono vengono legate a un quantificatore, ad esempio:
\begin{lstlisting}
val map : (a -> b) -> List a -> List b
\end{lstlisting}
in questo caso la funzione \texttt{map} avrà il seguente tipo:
\[ map : \forall \alpha, \beta . \; (\alpha \mapsto \beta) \mapsto List \; \alpha \mapsto List \; \beta \]

\subsubsection{Test di uguaglianza tra tipi}
Il test di uguaglianza tra tipi si differenzia parecchio tra le diverse nozioni di "tipo", inoltre, non sempre risulterà
utile avere una definizione di uguaglianza tra alcune nozioni di tipo. Partendo dalla nozione di mono-tipo, due
mono-tipi $ \tau $ e $ \tau' $ sono uguali se hanno i termini identici. Dato che langgg supporta la nozione di mono-tipo
higher-kinded, è banale asserire che:
\[ kindOf(\tau) \neq kindOf(\tau') \Longrightarrow \tau \neq \tau' \]
Per quanto riguarda i tipi qualificati, è necessario prendere in considerazione anche i predicati che precedono un
mono-tipo. Definiamo, quindi, il test di uguaglianza tra predicati. Siano $ (C \; \tau_1 \; ... \; \tau_n) $ e
$ (C' \; \tau_1' \; ... \; \tau_n') $ due constraints, essi sono uguali se:
\[ C = C' \wedge \forall i \in \{1, ..., n\}. \; \tau_i = \tau_i' \]
Ora possiamo definire il test uguaglianza per i tipi qualificati. Siano $ (P_1, ..., P_n \Rightarrow \tau) $ e
$ (Q_1, ..., Q_m \Rightarrow \tau') $ due tipi qualificati, essi sono uguali se:
\begin{enumerate}
    \item $ \tau = \tau' $
    \item $ \forall i \in \{1, ..., n\}. \; \exists j \in \{1, ..., m\}. \; P_i = Q_j $
    \item $ \forall j \in \{1, ..., m\}. \; \exists i \in \{1, ..., n\}. \; Q_j = P_i $
\end{enumerate}
Ora rimangono gli schemi di tipo. A differenza dei mono-tipi, qui le variabili possono essere quantificate, quindi non
basterebbe più definire il test di uguaglianza analizzando solamente i termini del mono-tipo. Nel codice sorgente in
\texttt{Compiler.Ast.Typed}, non vi è alcuna definizione di uguaglianza tra schemi di tipo poiché questa non è necessaria
a nessun'altra operazione.

\subsection{Polimorfismo ad-hoc}
langgg supporta il polimorfismo ad hoc esponendo costrutti chiamati \textit{proprietà}, le quali sono concettualmente
molto simili alle \textit{type classes} di Haskell. Ecco un esempio di definizione di proprietà in langgg:
\begin{lstlisting}
property Eq a =
    val (==) : a -> a -> Bool
    val (/=) : a -> a -> Bool
;;
\end{lstlisting}
Questo pezzo di codice produce idealmente due token corrispondenti ai metodi \texttt{(==)} e \texttt{(/=)},
i quali possono essere istanziati attraverso il meccanismo delle istanze che verrà presentato prossimamente. I token
appena costruiti avranno le seguenti firme:
\begin{lstlisting}
val (==) : Eq a => a -> a -> Bool
val (/=) : Eq a => a -> a -> Bool
\end{lstlisting}
Si noti come le firme effettive non siano le stesse di quelle date dall'utente, le quali risultano incomplete.
All'inizio della dicitura dei tipi effettivi, si può notare un \textit{constraint} o \textit{predicato} seguito da una
freccia, la quale è intesa come implicazione. I tipi dei metodi di proprietà avranno quindi la forma:
    \[ Pred(\overline{\alpha}) \Rightarrow ty(\overline{\alpha}) \]
dove \textit{Pred} è un predicato e \textit{ty} è un tipo qualunque sulle variabili $ \overline{\alpha} $.
Il polimorfismo ad hoc viene, dunque, supportato attraverso i predicati, i quali rappresentano delle ipotesi aggiuntive
sui tipi. L'istanziazione di una proprietà consiste nel dichiarare dei tipi che fungeranno da "caso particolare" per i
metodi di proprietà (i "modelli"), ad esempio, riprendendo la proprietà \texttt{Eq} del precedente pezzo di codice,
in langgg possiamo definire un'istanza del tipo:
\begin{lstlisting}
instance Eq Char =
    <implementazioni>
;;
\end{lstlisting}
I dettagli implementativi al momento sono omessi. In ogni caso, i metodi di istanza avranno le seguenti firme:
\begin{lstlisting}
val (==) : Char -> Char -> Bool
val (/=) : Char -> Char -> Bool
\end{lstlisting}
Si può notare come il predicato su \texttt{Eq} non esiste più.

\subsubsection{Estensioni del polimorfismo ad hoc}
Il meccanismo di polimorfismo ad hoc precedentemente presentato incontra numerose estensioni in langgg, alcune delle
quali impongono condizioni aggiuntive sul programma.

\subparagraph{Numero arbitrario di argomenti delle proprietà}
Nell'esempio con \texttt{Eq}, la proprietà possedeva soltanto un argomento, tuttavia, è possibile definire proprietà
con un numero arbitrario (ma fissato alla definizione) di argomenti ad esempio:
\begin{lstlisting}
property Stream s t =
    val new : t -> s t
    val yield : t -> s t -> s t
    val consume : s t -> (s t, t)
;;
\end{lstlisting}
Si noti che \texttt{Stream} ha 2 argomenti.

\subparagraph{Constraints sulle proprietà}
\`E possibile definire in langgg una proprietà della forma:
\begin{lstlisting}
property C1 a Char => C2 a =
    <metodi>
;;
\end{lstlisting}
Questo tipo di definizione consiste nell'aggiungere il predicato \texttt{C1 a} alla proprietà \texttt{C2 a}.
Semanticamente, questo impone la seguente condizione sul programma:
    \[ \forall type . \; \exists inst(C2, type) \Longrightarrow \exists inst(C1, type, Char) \]
dove $ inst(C, \overline{t}) $ è, banalmente, l'instanza con nome di proprietà $ C $ e tipi $ \overline{t} $. \`E
possibile aggiungere più di un predicato alla stessa proprietà.

\subparagraph{Polimorfismo higher-kinded}
Riprendiamo il precedente esempio con \texttt{Stream}:
\begin{lstlisting}
property Stream s t =
    val new : t -> s t
    val yield : t -> s t -> s t
    val consume : s t -> (s t, t)
;;
\end{lstlisting}
Gli argomenti di una proprietà sono sempre variabili di tipo. Come è già stato menzionato in precedenza, langgg supporta
tipi di kind arbitrari; gli argomenti delle proprietà non fanno eccezione da questo punto di vista, infatti, nell'esempio
si può notare come la variabile \textit{s} abbia kind (utilizzando la rappresentazione dei kind di Haskell):
    \[ * \mapsto * \]
mentre la variabile \textit{t} ha kind:
   \[ * \]

\subparagraph{Argomenti arbitrari delle istanze}
Gli argomenti di un'istanza possono essere tipi di forma arbitraria, ad esempio:
\begin{lstlisting}
property C x y =
    <metodi>
;;

instance C a (Tuple3 a (T b) (m b)) =
    <implementazioni>
;;
\end{lstlisting}
Confrontando il precedente codice langgg con il seguente codice Haskell che può considerarsi quanto meno concettualmente
equivalente:
\begin{lstlisting}
{-# LANGUAGE MultiParamTypeClasses #-}

class C x y where
    <metodi>

instance C a (a, T b, m b) where
    <implementazioni>
\end{lstlisting}
si ha che, compilando questo programma Haskell soltanto con l'estensione all'inizio del codice, si incorrerà nel
seguente messaggio d'errore da parte del compilatore:
\begin{lstlisting}
Illegal instance declaration for 'C a (a, T b, m b)'
(All instance types must be of the form (T a1 ... an)
where a1 ... an are *distinct type variables*,
and each type variable appears at most once in the instance head.
Use FlexibleInstances if you want to disable this.)
\end{lstlisting}
Come suggerisce l'ultima riga del messaggio d'errore, per definire un'istanza del genere in un programma Haskell è
necessario utilizzare l'estensione \texttt{FlexibleInstances} [7]. In langgg, a differenza di Haskell, quel tipo di instanza
è accettato di default. Il seguente vincolo sulla forma dei tipi riportato nel messaggio d'errore viene dunque rilassato:
    \[ TyCon(\overline{\alpha}) \]
dove $ \overline{\alpha} $ sono variabili di tipo distinte e $ TyCon $ è un costruttore di tipo. In seguito, verrà
mostrato quali vincoli che riguardano i constraints e le istanze possono essere rilassati e con quali conseguenze.

\subparagraph{Constraints sulle istanze}
L'utente ha anche la facoltà di definire istanze con uno o più predicati, ad esempio:
\begin{lstlisting}
instance Monad m => Stream m String =
    <implementazioni>
;;
\end{lstlisting}
questo tipo di definizione genererà metodi di istanza con le seguenti firme:
\begin{lstlisting}
val new : Monad m => String -> m String
val yield : Monad m => String -> m String -> m String
val consume : Monad m => m String -> (m String, String)
\end{lstlisting}
Il constraint sull'istanza viene quindi applicato al tipo dei metodi di istanza.

\subsubsection{Condizioni sui constraint}
I constraints rappresentano un modo per "restringere" i possibili tipi che possono istanziare una o più variabili di
tipo. I tipi nelle firme delle variabili (nonché i type-hinting) possono possedere zero o più constraint; lo stesso
vale, come viene mostrato nei paragrafi precedenti, anche per le proprietà e per le istanze. Esistono, però, dei
vincoli sulla forma dei constraint. Come viene mostrato in [8] e [9], esistono condizioni (di Paterson) sufficienti
affinché l'algoritmo di risoluzione delle istanze di Haskell termini. Prima di presentarle, diamo alcune notazioni:
\newline Dato un costrutto $ K $ in cui compaiono dei constraints $ C \Rightarrow D $, definiamo
\begin{itemize}
    \item $ C $ come \textit{Contesto} del costrutto $ K $;
    \item $ H $ come \textit{Testa} del costrutto $ K $.
\end{itemize}
Ora presentiamo le condizioni di Paterson:
\begin{itemize}
    \item il contesto \textit{C} di una dichiarazione di type-class può menzionare solamente variabili di tipo e
    le variabili di tipo sono distinte in ogni singolo constraint in \textit{C};
    \item Per ogni dichiarazione di istanza $ C \Rightarrow TyCl \; t_1 ... t_n $, nessuna variabile di tipo ha
    più occorrenze nel contesto $ C $ rispetto alla testa $ TyCl \; t_1 ... t_n $.
    \item Per ogni dichiarazione di istanza $ C \Rightarrow TyCl \; t_1 ... t_n $, ogni constraint nel contesto
    $ C $ ha meno costruttori e variabili di tipo (presi insieme e contando le ripetizioni) rispetto alla testa
    $ TyCl \; t_1 ... t_n $.
    \item Per ogni due dichiarazioni di istanze $ C \Rightarrow TyCl \; t_1 ... t_n $,
    $ C' \Rightarrow TyCl \; t_1' ... t_n' $, non deve esistere una sostituzione $ \varphi $ tale che:
    $ \varphi(t_1) = \varphi(t_1') $, ..., $ \varphi(t_n) = \varphi(t_n') $.
\end{itemize}
Informalmente, l'obiettivo è avere sempre dei contesti più "piccoli" rispetto alle teste. La politica di langgg è
simile e applica i seguenti vincoli:
\begin{enumerate}
    \item Per ogni constraint $ c $, $ c $ deve contenere almeno una variabile di tipo, ovvero:
    \[ \forall \; constraint =: c.\; \exists \; tyvar =: v.\; v \in c \]
    \item Per ogni istanza $ ctx \Rightarrow h $, il numero di occorrenze di ogni singola variabile $ v $ nel contesto
    $ ctx $ deve essere minore o uguale rispetto al numero di occorrenze di $ v $ nella testa $ h $, ovvero:
    \[ \forall \; instance =: (ctx \Rightarrow h).\; \forall \; tyvar =: v.\; v \in instance
    \Longrightarrow occ(v, ctx) \leq occ(v, h) \]
    \item Per ogni istanza $ ctx \Rightarrow h $, le variabili di tipo di $ ctx $ devono essere innestate in meno
    costruttori di tipo rispetto alle variabili di tipo di $ h $ (contando le variabili tutte insieme), ovvero: \newline
    \[ \forall \; instance =: (ctx \Rightarrow h).\; countWrapVars(ctx) < countWrapVars(h) \]
\end{enumerate}
dove $ occ(v, k) $ è la funzione che conta le occorrenze della variabile di tipo $ v $ nel costrutto $ k $ e
$ countWrapVars(k) $ è la funzione che conta in quanti costruttori di tipo nel costrutto $ k $ sono innestate le
variabili di tipo (sommando il risultato per tutte le variabili di tipo incontrate). Il codice che implementa questi
controlli risiede nel modulo \texttt{Compiler.Constraints.Check}.

\subsection{Kind-inference}
%TODO

\subsection{Data constructors}
Una delle tabelle di simboli che appare nel modulo \texttt{Compiler.Types.Table} è \texttt{DataConsTable}. In essa
vengono salvati i \textit{data constructor} associati ai loro tipi. I costruttori - che nell'AST vengono rappresentati
dal token \texttt{ADTConstructor} - vengono trasformati nel token \texttt{NotedVal} presente nel modulo
\texttt{Compiler.Ast.Typed} che consiste nella seguente coppia:
\[ < dataConRep, type > \]
dove $ dataConRep $ è la rappresentazione sotto forma di stringa del data constructor, mentre $ ty $ è il tipo del
costruttore. Per quanto riguarda il tipo del costruttore, prendiamo in considerazione il seguente esempio di codice
langgg:
\begin{lstlisting}
type Foo x y = Bar Int (M x) y
\end{lstlisting}
In questa definizione di tipo di dato algebrico, vi è un solo costruttore: \texttt{Bar}. Il suo tipo è il seguente:
\[ \forall x, y. \; Int \mapsto M \; x \mapsto y \mapsto Foo \; x \; y \]
Il tipo di ritorno è sempre dato dalla definizione del tipo. Il modulo che si occupa di trasformare i token
\texttt{ADTConstructor} in \texttt{NotedVal} e aggiungerli nella tabella \texttt{DataConsTable} è
\texttt{Compiler.Types.Builder.Cons}.

\subsection{Constraint constructors}
Dopo il check sui constraints e la generazione di data constructors, il compilatore si occupa di generare i cosiddetti
"\textit{constraint constructors}", ovvero token che fungono da modelli per la costruzione di predicati. Il modulo
che li genera è \texttt{Compiler.Types.Tables}; esso prende in input i token dell'AST che rappresentano le proprietà
(\texttt{Interface}) e da essi costruisce i token tipati \texttt{LangNewConstraint} e li inserisce nella tabella
\texttt{ConstraintsTable}. \`E compito di questo modulo controllare che le classi non formino cicli tra loro, ad
esempio, il seguente programma viene rifiutato dal compilatore:
\begin{lstlisting}
property Bar (M a) Int => Foo a =
    <metodi>
;;

property Foo (K x Char) => Bar x y =
    <metodi>
;;
\end{lstlisting}
Si noti come i vincoli sui constraints vengano tutti rispettati.

\subsection{Costruzione delle istanze}
Nel modulo \texttt{Compiler.Types.Builder.Instances} vengono create le seguenti 3 tabelle:
\begin{itemize}
    \item \texttt{InstsTable}, ovvero la tabella che contiene i bindings (sotto forma di token dell'AST) delle istanze;
    \item \texttt{PropMethodsTable}, ovvero la tabella che contiene i metodi delle proprietà sotto forma di token
    tipati;
    \item \texttt{ImplTable}, ovvero la tabella che contiene i constraints che derivano dalle istanze definite
    dall'utente;
\end{itemize}
Per quanto riguarda l'ultima tabella, data la definizione di un'istanza:
\begin{lstlisting}
instance Eq Char =
    <implementazioni>
;;
\end{lstlisting}
la testa \texttt{Eq Char} ha la forma di un constraint, nonostante non rispetti uno dei vincoli sui constraints (un
constraint deve avere almeno una variabile di tipo), infatti l'istanza viene salvata sotto forma di constraint
(\texttt{LangSpecConstraint}).
Le tre tabelle vengono create in un unico modulo per una questione di efficienza (i token delle istanze vengono visitati
una sola volta). Inoltre, in questo
modulo viene effettuato il controllo del vincolo sull'esistenza dei predicati delle proprietà (cfr. paragrafo "constraints
delle proprietà" in "Estensioni del polimorfismo ad hoc"). Prima di inserire i bindings delle istanze nella
tabella \texttt{InstsTable}, viene eseguita una fase di desugaring su di essi. Il problema nasce dal fatto che, data
una proprietà, può esistere un numero arbitrario di istanze e con esse, un numero arbitrario di metodi con lo stesso
nome, perciò è necessario identificare univocamente i metodi di ogni singoli istanza. Il modulo
\texttt{Compiler.Desugar.Names} si occupa di, dato il nome di una variabile e una sequenza di constraints (gli argomenti
di un'istanza), creare un identificatore univoco che non può essere uguale a nessun altro identificatore nel programma.

\subsection{Preparazione alla type-inference}
Prima di effettuare la type-inference è necessario fare alcune considerazioni ed effettuare alcune computazioni.
Innazitutto, il type-system di riferimento è \textit{Hindley-Milner} (o Damas-Hindley-Milner, in seguito lo indicheremo con HM)
con alcune estensioni che riguardano il costrutto del pattern matching, l'inferenza di definizioni ricorsive e la
risoluzione delle istanze. Il modulo che si occupa della preparazione alla type-inference è \texttt{Compiler.Types.Prepare}
Introdurremo il type-system in modo preciso prossimamente (cfr. Type-inference), tuttavia, ora presentiamo alcune
caratteristiche del type-system che è bene conoscere come premessa alla preparazione della type-inference.
Innanzitutto, HM viene descritto formalmente da un insieme di \textit{regole} le quali si occupano di "tipare"
espressioni di un formalismo fissato: una versione del lambda-calcolo estesa con un costrutto di espressioni "let..in".
Una delle regole è quella sull'inferenza del tipo di un simbolo (la regola la chiameremo chiamiamo \textbf{Var})
la quale, informalmente, sostiene che: data l'ipotesi di un simbolo $ x $ con schema di tipo $ \sigma $ nel contesto di
un ambiente di tipizzazione $ \Gamma $ e $ \tau $ l'istanziazione del tipo $ \sigma $, si conclude che il simbolo
$ x $ ha tipo $ \tau $.
Un'altra regola utile è quella
sull'inferenza delle definizioni mutualmente ricorsive. In particolare, essa sostiene che, l'inferenza di definizioni
mutualmente ricorsive avviene in "gruppo", ovvero un insieme $ {f_1, ..., f_n} $ di simboli mutualmente ricorsivi
tra loro vengono considerati nel loro insieme e non singolarmente (regola \textbf{Rec}).
Queste regole serviranno come premessa ad alcune fasi nella preparazione della type inference.

\subsubsection{Bindings delle istanze}
\`E bene notare come in Core non esista un costrutto particolare per i bindings delle istanze, inoltre, il
costrutto di GHC che rappresenta le istanze (\texttt{ClsInst}) non porta con sè informazioni che riguardano i
bindings [10].
Perciò, è in un qualche modo necessario gestire i bindings delle istanze. La politica del compilatore è quella di
aggiungerli nell'insieme di bindings da dare in input all'algoritmo di type-inference. La presenza di bindings con lo
stesso identificatore è stata già risolta (cfr. Costruzione delle istanze e dispatch statico).

\subsubsection{Simboli innestati univoci}
Prima della type-inference, vengono visitate tutte le espressioni dei bindings e vengono creati nuovi identificatori
per ogni definizione innestata di variabile (costrutto \texttt{let..in}). I nuovi identificatori sono resi univoci in
tutto il programma. Il modulo che crea e garantisce che i nuovi identificatori sono univoci è
\texttt{Compiler.Desugar.Names}. La proprietà di unicità degli identificatori innestati è molto importante, vedremo in
seguito il motivo (cfr. type-inference).

\subsubsection{Clusters di definizioni mutualmente ricorsive}
Come è stato già menzionato precedentemente, le definizioni mutualmente ricorsive devono essere considerate come insiemi
e non singolarmente. Perciò è necessario distinguere due tipi di bindings, quelli mutualmente ricorsivi e i restanti:
\begin{lstlisting}
data RawBinding =
      RawNonRec (Raw.SDUnion With.ProgState)
    | RawRec [Raw.SDUnion With.ProgState]
\end{lstlisting}
La precedente definizione è nel modulo \texttt{Compiler.Types.Prepare.Lib} e divide i bindings dell'AST in bindings
non ricorsivi e bindings mutualmente ricorsivi. Rimane, quindi, da dividere i bindings del programma. Prima di presentare
l'algoritmo, bisogna effettuare una precisazione molto importante. In precedenza, abbiamo aggiunto i bindings delle
istanze alla lista dei bindings del programma, cambiando, però, gli identificatori, rendendoli univoci all'interno del
programma. Per dividere riconoscere i bindings mutualmente ricorsivi è necessaria una funzione che calcoli le dipendenze
di una definizione. Nelle espressioni, in generale, possono essere menzionati i metodi delle proprietà, ma non possono,
in alcun modo, essere menzionati i metodi delle istanze. Inoltre, il tipo dei metodi delle proprietà è sempre noto a
priori e non è possibile, prima della type-inference, inferire le istanze (cfr. static dispatch) giuste dei metodi.
Nel calcolo delle dipendenze, i metodi di proprietà possono, quindi, essere esclusi. La funzione \textit{depsOf}, la quale
prende in input un binding \texttt{b} dell'AST e la tabella \texttt{PropMethodsTable}, calcolerà le dipendenze di
\texttt{b}, escludendo le dipendenze che provengono dalla tabella dei metodi di proprietà. L'insieme dei bindings di
un programma può essere visto come un grafo orientato $ G $ in cui:
\begin{itemize}
    \item i nodi sono i bindings;
    \item gli archi sono le dipendenze di un binding.
\end{itemize}
Il problema di trovare i clusters di definizioni mutualmente ricorsive corrisponde a trovare le \textit{componenti
fortemente connesse} del grafo $ G $. Il modulo che implementa l'algoritmo è \texttt{Compiler.Types.Prepare.Recursion}
e utilizza la libreria \texttt{Data.Graph}.

\subsubsection{Sorting dei bindings}
A questo punto, abbiamo una lista di \texttt{RawBinding}. Possiamo fare la seguente osservazione: i bindings possono
essere visti come un grafo orientato aciclico $ G $, in cui, come prima:
\begin{itemize}
    \item i nodi sono i bindings;
    \item gli archi sono le dipendenze di un binding.
\end{itemize}
L'unica differenza è sull'aciclicità del grafo. Questa proprietà è garantita dal seguente fatto: se esistesse un ciclo
in $ G $, allora l'algoritmo di raggruppamento dei clusters l'avrebbe trovato e avrebbe creato un cluster di definizioni
mutualmente ricorsive tra loro. La regola di inferenza \textbf{Var} impone che si conosca sempre lo schema di tipo di
un simbolo, perciò, è necessario, prima di effettuare la type-inference, ordinare i bindings in base alle loro dipendenze.
L'ordinamento viene effettuato nel modulo \texttt{Compiler.Types.Prepare.Sort} e l'algoritmo utilizzato è un'estensione
dell'insertion-sort, dove, la nozione di ordinamento è data dalle dipendenze dei bindings, ovvero: \newline
Siano $ b $ e $ b' $ due bindings, si ha che:
\begin{itemize}
    \item $ b > b' $, se $ b' $ è una dipendenza diretta di $ b $ oppure esistono dei bindings $ c_1, ..., c_n $ tali che:
    \newline $ (b > c_1) \wedge (c_1 > c_2) \wedge ... \wedge (c_{n-1} > c_n) \wedge (c_n > b') $;
    \item $ b = b' $, se la componente di $ b $ in $ G $ non è raggiungibile da nessun nodo della componente $ b' $.
\end{itemize}
la proprietà di transitività di questa nozione di ordinamento è garantita dall'assenza di cicli all'interno del grafo.
Di seguito vi è l'algoritmo di sorting di una singola componente del grafo:
\begin{lstlisting}
sortComponent(bindings, remaining, component):
    match bindings, remaining with
        [], [] -> component
        [], (_ : _) -> sortComponent remaining [] component
        (b : t), _ ->
            let (inserted, component') = tryInsert b component in
                if inserted
                then sortComponent t remaining component'
                else sortComponent t (addTail b remaining) component 
\end{lstlisting}
L'algoritmo prende in input i bindings di una componente, i bindings rimanenti e la componente già ordinata. Ora
presentiamo l'algoritmo di inserzione di un binding in una componente già ordinata:
\begin{lstlisting}
tryInsert(binding, component):
    match component with
        [] -> [component]
        (b : t) ->
            if b in depsOf(binding)
            then tryInsert binding t
            else if binding in depsOf(b)
            then (True, binding : component)
            else (False, component)
\end{lstlisting}
Ora abbiamo implementato una versione alternativa dell'insertion sort in cui gli inserimenti vengono effettuati
solamente se si è a conoscenza che il binding da inserire fa parte delle dipendenze dirette di un altro binding già
inserito nella componente. Inoltre, se non vi sono abbastanza informazioni per inserire un binding in una componente,
il suo inserimento viene "rimandato" (viene inserito nei bindings rimanenti) e verrà effettuato in un'iterazione
successiva. Il codice si trova nel modulo \texttt{Compiler.Types.Prepare.Sort}.

Dopo l'ordinamento dei bindings, è garantito che, ogni qual volta verrà inferito un binding, la premessa
della regola \textbf{Var} sia vera.

\subsection{Type-inference}
langgg permette all'utente di indicare o non indicare il tipo di una variabile. Nel caso non venga indicato, il
compilatore dovrà inferire il tipo della variabile definita, quindi dovrà fare una "scelta". Per farlo, dovrà prima
inferire il tipo dell'espressione legata alla variabile, ad esempio:
\begin{lstlisting}
type Maybe a = Nothing | Just a
let x = Nothing
\end{lstlisting}
Si può affermare che l'espressione legata alla variabile $ x $ abbia tipo $ Maybe \; \alpha $. Ora, il compilatore
deve scegliere un tipo da sostituire alla variabile di tipo $ \alpha $. Se la scelta fosse arbitraria, ad esempio
$ Int $, l'utilizzo di $ x $ sarebbe limitato solo a un tipo ovvero $ Maybe \; Int $. Un'altra possibile soluzione
potrebbe essere associare a $ x $ il tipo $ Maybe \; a $. Tuttavia, anche questa scelta risulterebbe limitante in quanto,
come è stato già esposto nella sezione sul type-system (cfr. Schemi di tipi), la variabile di tipo $ \alpha $
denoterebbe un tipo fissato non ancora conosciuto. L'introduzione di uno schema di tipo rappresenta una scelta
"più generale":
\[ x : \forall \alpha. \; Maybe \; \alpha \]
In questo caso, $ x $ può avere molteplici tipi.

\subsubsection{Damas-Hindley-Milner}
Come è stato già menzionato precedentemente, il sistema di tipi di langgg si basa sul type-system di Damas-Hindley-Milner.
L'algoritmo di inferenza su cui si basa inferisce il tipo più \textit{generale} possibile. Tuttavia, nella letteratura,
vengono presentati due algoritmi principali, ma nella pratica, solo uno di essi è implementato dai compilatori dei
linguaggi di programmazione. Verranno entrambi menzionati, ma solo le regole di inferenza dell'algoritmo effettivamente
implementato verranno esposte:
\begin{itemize}
    \item \textit{Algoritmo W}, è l'algoritmo effettivamente utilizzato dalle implementazioni, in quanto tiene traccia
    delle sostituzioni generate dalle eventuali unificazioni (cfr. Unificazione) e le applica all'ambiente di
    tipizzazione. Proprio a causa della gestione delle sostituzioni, la complessità computazionale dell'algoritmo
    nel caso peggiore è esponenziale.
    \item \textit{Algoritmo J}, è un algoritmo più efficiente di \textit{W} (lineare nella lunghezza dell'espressione),
    tuttavia, esso non gestisce le sostituzioni, o almeno, esse vengono considerate come side-effects. Viene
    presentato in letteratura come alternativa efficiente a \textit{W}.
\end{itemize}

\subsubsection{Regole di inferenza}
Come è stato già anticipato, HM viene presentato sotto forma di \textit{regole}, le quali hanno la seguente forma:
\newline
\[ \infer[\textbf{Regola}]{Conclusione}{Premesse} \]
dove le premesse sono un insieme di \textit{giudizi} e \textit{predicati} e la conclusione è un \textit{giudizio}. Un
\textit{giudizio} è un'affermazione sul tipo di un simbolo, ad esempio:
\[ x : \sigma \]
afferma che il simbolo $ x $ ha tipo $ \tau $. HM necessita, inoltre, di un modo per "tener traccia" dei giudizi,
ovvero un modo per accoppiare un simbolo con un tipo. Introduciamo, quindi,
un altro componente: il \textit{contesto} o \textit{ambiente di tipizzazione}. In generale, i giudizi terranno conto
del contesto, infatti avranno la seguente forma:
\[ \Gamma \vdash_W x : \sigma \]
questa scritta afferma che sotto le ipotesi in $ \Gamma $, il token $ x $ ha tipo $ \sigma $.
Ora verranno elencate le regole di inferenza:

\paragraph{Inferenza di variabile}
Prima di presentare di la regola d'inferenza delle variabili è necessario due ulteriori regole. La prima è la
regola di specializzazione e introduce una nozione d'ordine parziale tra tipi:
\[ \infer[\textbf{Spec}]{\forall \alpha_1 ... \forall \alpha_n. \; \tau \sqsubseteq \forall \beta_1 ... \beta_m. \; \tau'}{\tau' = \{ \alpha_i \mapsto \tau_i \}\tau & \beta_i \notin free(\forall \alpha_1 ... \forall \alpha_n . \; \tau)} \]
Questa regola sostiene che se esiste una sostituzione $ S = \{ \alpha_i \mapsto \tau_i \} $ tale che $ \tau' = S \tau $,
allora la versione "quantificata" dei mono-tipi $ \tau $ e $ \tau' $ rispetta la relazione d'ordine parziale
$ \sqsubseteq $. Nella premessa vi è un'ulteriore condizione che afferma che le variabili quantificate di $ \tau' $
non devono apparire come variabili libere in $ \forall \alpha_1 ... \alpha_n. \; \tau $; questo perché le variabili
non legate da un quantificatore (quindi libere) non devono essere sostituite, bensì devono essere trattate come costanti.
All'interno del codice, i token tipati che implementano la type-class \texttt{SpecType} in \texttt{Compiler.Ast.Typed}
permettono l'applicazione di una sostituzione al loro tipo.
La prossima regola rappresenta l'algoritmo di instanziazione:
\[ \infer[\textbf{Inst}]{\Gamma \vdash_W e : \tau}{\Gamma \vdash_W e : \sigma & \sigma \sqsubseteq \tau} \]
Questa regola è utile per istanziare uno schema di tipo in mono-tipo. \`E chiaro che è necessario tener conto delle
eventuali variabili libere nello schema di tipo $ \sigma $, ma queste vengono gestite dalla regola di specializzazione.
Ora, possiamo esporre la regola di inferenza di una variabile, la quale è stata già introdotta in precedenza, seppur
in maniera informale.
\[ \infer[\textbf{Var}]{\Gamma \vdash_W x : \tau, \; \emptyset}{x : \sigma \in \Gamma & \tau = inst(\sigma)} \]
\`E doveroso notare che nella conclusione, oltre al giudizio sul tipo della variabile, vi è un altro valore in "output",
ovvero le eventuali sostituzioni generate dall'inferenza dei costrutti coinvolti. In questo non vi è alcuna sostituzione.

\paragraph{Inferenza di applicazione}
La prossima regola serve per inferire l'applicazione di due espressioni:
\[ \infer[\textbf{App}]{\Gamma \vdash_W e_0 \; e_1 : S_2\tau', \; S_2S_1S_0}{\Gamma \vdash_W e_0 : \tau_0, \; S_0 & S_0\Gamma \vdash_W e_1 : \tau_1, \; S_1 & \tau' = newvar & S_2 = mgu(S_1\tau_0, \tau1 \mapsto \tau')} \]
Vi sono due nuovi operatori:
\begin{itemize}
    \item $ newvar $, il quale ritorna una nuova variabile di tipo $ \alpha $ tale che $ \alpha \notin free(\Gamma) $;
    \item $ mgu $, il quale rappresenta l'algoritmo di unificazione che verrà presentato dettagliatamente nel prossimo
    paragrafo. Tralasciando, quindi, i dettagli implementativi, tale operatore serve per trovare il tipo più generale.
    Come risultato, fornisce una sostituzione $ S_2 $, la quale viene successivamente applicata al mono-tipo $ \tau' $
    per ottenere il tipo di ritorno del costrutto di applicazione.
\end{itemize}
Si noti che, a differenza di \textbf{Var}, in questa regola vi sono tre sostituzioni in output
\begin{itemize}
    \item $ S_0 $ derivante dall'inferenza della prima espressione;
    \item $ S_1 $ derivante dall'inferenza della seconda espressione;
    \item $ S_2 $ derivante dall'esecuzione dell'algoritmo di unificazione tra tipi;
\end{itemize}
Nell'inferenza di $ e_1 $, l'ambiente di tipizzazione di riferimento è $ \Gamma $ a cui viene applicata la sostituzione
$ S_0 $. Una possibile ottimizzazione è la seguente:
\[ \infer[\textbf{App}]{S_0\Gamma \vdash_W e_0 \; e_1 : S_2\tau', \; S_2S_1}{\Gamma \vdash_W e_0 : \tau_0, \; S_0 & S_0\Gamma \vdash_W e_1 : \tau_1, \; S_1 & \tau' = newvar & S_2 = mgu(S_1\tau_0, \tau1 \mapsto \tau')} \]
La sostituzione $ S_0 $ viene, quindi, spostata dall'output direttamente all'ambiente di tipizzazione. Questo per evitare
di applicare la sostituzione all'ambiente di tipizzazione due volte: una prima di inferire $ e_1 $, una dopo il risultato
di output (si presume che le sostituzioni vengano tutte applicate).

\paragraph{Unificazione}
L'unificazione è quel processo di risoluzione di equazioni tra espressioni "simboliche". In generale, i mono-tipi nel
type-system utilizzato in HM (e conseguentemente anche quello utilizzato da langgg) possono essere considerati come
termini di un'equazione. Si parla di mono-tipi, poiché l'unificazione non prevede la quantificazione delle variabili
all'interno di un'equazione. Un problema di unificazione è un insieme finito di equazioni:
\[ \{ \tau_1 = \tau_1' \; ... \; \tau_n = \tau_n' \} \]
dove $ \tau_i, \tau_i' $ sono dei mono-tipi. La soluzione di un problema di unificazione è data da una sostituzione
$ S = \{ \alpha_j \mapsto \mu_j \} $, dove $ \alpha_j $ è una variabile di tipo e $ \mu_j $ è un mono-tipo, tale che:
\[ \forall i \in \{1, ..., n\}. \; S\tau_i = S\tau_i' \]
Il codice sorgente che si occupa dell'unificazione si trova nel modulo \texttt{Compiler.Ast.Typed}, in particolare,
la funzione \texttt{rawUnify} implementa l'algoritmo di unificazione, osserviamo la sua firma:
\begin{lstlisting}
rawUnify
    :: LangHigherType a
    -> LangHigherType a
    -> IsSpecTest
    -> Either (UnificationError a) (Substitution a)
\end{lstlisting}
Notiamo subito che vi sono tre argomenti e che il tipo di ritorno è un result-type.
\begin{lstlisting}
data UnificationError a =
      UnmatchTypes (LangHigherType a) (LangHigherType a)
    | TrySwap (LangHigherType a) (LangHigherType a)
    | OccursCheck (LangHigherType a) (LangHigherType a)
    | UnmatchKinds (LangHigherType a) (LangHigherType a)

type IsSpecTest = Bool
\end{lstlisting}
Il tipo \texttt{UnificationError} possiede 4 casi d'errore e tutti prendono in input due mono-tipi:
\begin{itemize}
    \item \texttt{UnmatchTypes}, ritornato quando non vi è alcuna soluzione all'equazione tra due mono-tipi;
    \item \texttt{TrySwap}, simile a \texttt{UnmatchTypes} nella semantica, ma indica all'algoritmo di non terminare
    subito, analizzeremo approfonditamente questo caso in seguito;
    \item \texttt{OccursCheck}, ritornato quando vi è il tentativo di risolvere un problema del tipo:
        \[ \alpha = f \; ... \; \alpha \; ...  \]
    Questo tipo di equazione porterebbe come risultato un termine infinito visto che $ \alpha $ è sotto-termine di
    se stesso;
    \item \texttt{UnmatchKinds}, ritornato quando i kinds di due mono-tipi non coincidono. In questo caso, non vi
    può essere alcuna soluzione all'equazione, si pensi, ad esempio, a:
        \[ M \; \alpha = M \; Int \; \beta \]
\end{itemize}
Ora passiamo all'algoritmo vero e proprio, il quale sarà presentato mostrando direttamente soltanto una parte di esso
all'interno del codice sorgente in \texttt{rawUnify}:
\begin{lstlisting}
rawUnify monoTy monoTy' isSpecTest =
    case unification monoTy monoTy' empty of
        Left err -> Left err
        Right vvars -> Right $ elems vvars
    where
        unification lhty lhty' vvars
            | not $ sameInfrdKindOf lhty lhty' =
                Left $ UnmatchKinds lhty lhty'
            | occursCheck lhty lhty' =
                Left $ OccursCheck lhty lhty'
            | tyVarAndConcrete lhty lhty' =
                if isSpecTest
                then Left $ UnmatchTypes lhty lhty'
                else unification lhty' lhty vvars
            | bothConcrete lhty lhty' =
                if headEq lhty lhty'
                then argsUnification lhty lhty' vvars
                else Left $ UnmatchTypes lhty lhty'
            | bothTyVar lhty lhty' && argsOf lhty' > argsOf lhty =
                if isSpecTest
                then Left $ UnmatchTypes lhty lhty'
                else unification lhty' lhty vvars
            | otherwise =
                argsUnification lhty lhty' vvars

        argsUnification =
            if isSpecTest
            then unifyOnArgs
            else twoChancesUnifyArgs

        twoChancesUnifyArgs lhty lhty' vvars =
            case unifyOnArgs lhty lhty' vvars of
                Left err @ (TrySwap _ _) ->
                    case unifyOnArgs lhty' lhty vvars of
                        Left _ -> Left err
                        ok @ (Right _) -> ok
                err @ (Left _) -> err
                ok @ (Right _) -> ok

        <resto del codice>
--$ rm this when building
\end{lstlisting}
I commenti nel codice sorgente sono stati rimossi per evitare confusione. Come è stato fatto notare in precedenza,
l'algoritmo prende in input tre argomenti, di cui i primi due sono i mono-tipi sui quali si vuole calcolare l'unificazione.
Il terzo argomento è un flag booleano che denota se \texttt{rawUnify} deve essere un test di specializzazione
(\texttt{True}) o semplicemente l'algoritmo di unificazione (\texttt{False}). Un test di specializzazione è l'equivalente
dell'unificazione, ma può essere fatta in un solo "verso", ovvero se, dati due mono-tipi $ \tau $ e $ \tau' $ e data
la sostituzione di ritorno $ S = \{ \alpha_i \mapsto \tau_i \} $ conseguente alla valutazione dell'unificazione di
$ \tau $ e $ \tau' $, vale:
\[ \forall \alpha_i \in left(S). \; \alpha_i \in \tau' \]
dove con $ \alpha_i \in left(S) $ si intendono solamente le variabili di tipo nella parte sinistra di una sostituzione,
ovvero quelle che devono essere sostituite. Questo rende l'unificazione più stringente
e ciò è utile quando è richiesto che uno dei due mono-tipi non venga modifcato,
ad esempio, quando deve essere effettuato il type-check con un tipo che deriva da una annotazione di tipo (type-hinting).
Infatti, ci si aspetta che, data un'espressione con type-hinting, l'espressione abbia esattamente il tipo indicato
nell'annotazione di tipo.

L'obiettivo dell'algoritmo è riportarsi in una situazione tale che l'equazione tra i due mono-tipi ha la seguente forma:
\[ \alpha = \tau \]
dove $ \alpha $ è una variabile di tipo e $ \tau $ è un mono-tipo. Questo perché tale equazione ha la forma di una
sostituzione: $ \alpha = \tau $.
Tuttavia, nell'algoritmo, viene considerata la forma:
\[ \tau = \alpha \]
Di fatto, però, la semantica dell'unificazione non cambia; i termini dell'equazione possono essere anche invertiti,
cambiando, però, il "verso" dei controlli e delle operazioni nell'algoritmo.
Per ottenere un'equazione di quella forma vi sono due operazioni fondamentali:
\begin{itemize}
    \item \textit{swap}, in cui, se deve essere effettuata l'unificazione di due mono-tipi $ \tau $ e $ \tau' $,
    l'ordine di quest'ultimi viene scambiato. Questa operazione è utile quando il mono-tipo $ \tau' $ è più
    "specializzato" rispetto a $ \tau $. In generale, il mono-tipo più generale (o meno specializzato) possibile
    è una variabile singoletto, la quale, come è stato menzionato prima, deve stare nella parte destra dell'equazione.
    \item \textit{decompose}, in cui, se deve essere effettuata l'unificazione di due mono-tipi $ \tau $ e $ \tau' $,
    viene effettuata l'unificazione tra i vari argomenti dei due mono-tipi, raccogliendo successivamente le
    varie sostituzioni ottenute. Questa operazione è utile quando un'operazione di \textit{swap} non è vantaggiosa (ovvero
    il mono-tipo $ \tau $ è già "più specializzato" di $ \tau' $). Essa permette di considerare mono-tipi più piccoli.
\end{itemize}

Analizzando il codice, la prima chiamata viene fatta a \texttt{unification}, la quale considera varie casistiche:
\begin{enumerate}
    \item
    \begin{lstlisting}
| not $ sameInfrdKindOf lhty lhty' =
    Left $ UnmatchKinds lhty lhty'
    \end{lstlisting}
    Nel primo caso viene effettuato un controllo sui kind dei due mono-tipi. Se sono diversi, viene restituito un errore;
    \item
    \begin{lstlisting}
| occursCheck lhty lhty' =
    Left $ OccursCheck lhty lhty'
--$ rm this when building
    \end{lstlisting}
    Nel secondo caso viene effettuato un altro controllo: il cosiddetto \textit{occurs check}. Se uno dei due mono-tipi
    ha la forma di una variabile di tipo e quest'ultima compare nell'altro mono-tipo, allora viene ritornato un errore.
    \item
    \begin{lstlisting}
| tyVarAndConcrete lhty lhty' =
    if isSpecTest
    then Left $ UnmatchTypes lhty lhty'
    else unification lhty' lhty vvars
--$ rm this when building
    \end{lstlisting}
    Nel terzo caso vi è il primo controllo sulla struttura dei mono-tipi: se \texttt{lhty} ha come testa una variabile
    di tipo e \texttt{lhty'} ha come testa un tipo concreto, allora vi è un'operazione di \textit{swap}, ovvero vi è
    una chiamata ricorsiva di \texttt{unification} con gli argomenti invertiti. Se l'unificazione è \textit{strict},
    viene ritornato un errore, in quanto una variabile di tipo, per definizione, non è più specializzata di un tipo
    concreto. In questo caso, l'operazione di \textit{swap} non può essere effettuata in quanto verrebbe a meno il vincolo
    secondo il quale le variabili del primo mono-tipo (\texttt{lhty}) non devono essere sostituite.
    \item
    \begin{lstlisting}
| bothConcrete lhty lhty' =
    if headEq lhty lhty'
    then argsUnification lhty lhty' vvars
    else Left $ UnmatchTypes lhty lhty'
--$ rm this when building
    \end{lstlisting}
    Nel quarto caso viene testato se entrambi i mono-tipi hanno tipi concreti come testa; se così fosse, le teste
    devono rappresentare lo stesso tipo concreto, altrimenti viene restituito un errore, in quanto non esisterebbe
    alcuna sostituzione che permetterebbe l'uguaglianza tra i due mono-tipi. Se, invece, le teste sono uguali, allora
    viene eseguita un'azione di \textit{decompose}, ovvero vengono effettuate delle chiamate ricorsive sugli argomenti
    dei due mono-tipi. Analizzeremo la funzione \texttt{argsUnification} in seguito.
    \item
    \begin{lstlisting}
| bothTyVar lhty lhty' && argsOf lhty' > argsOf lhty =
    if isSpecTest
    then Left $ UnmatchTypes lhty lhty'
    else unification lhty' lhty vvars
--$ rm this when building
    \end{lstlisting}
    Nel quinto caso viene controllato se entrambi i mono-tipi hanno variabili di tipo come testa e se il numero di
    argomenti del secondo mono-tipo sono strettamente maggiori di quelli del primo. In questo caso, vi è un'operazione
    di \textit{swap} e la conseguente chiamata ricorsiva. Come prima, se l'unificazione è \textit{strict},
    l'operazione di \textit{swap} non può essere effettuata.
    \item
    \begin{lstlisting}
| otherwise =
    argsUnification lhty lhty' vvars
    \end{lstlisting}
    Nell'ultimo caso, vengono valutati tutti i casi restanti: quello che viene eseguito è un'azione di decompose sugli
    argomenti dei due mono-tipi.
\end{enumerate}

La funzione \texttt{argsUnification} implementa l'azione di \textit{decompose}. Per farlo, è necessario "accoppiare" gli
argomenti dei mono-tipi e questo avviene in \texttt{unifyOnArgs} che si occupa di effettuare le eventuali chiamate
ricorsive. Senza entrare nei dettagli implementativi di \texttt{unifyOnArgs}, una volta che le chiamate ricorsive sono
state effettuate, se non vi è stato alcun errore, allora l'output sarà una sequenza di sostituzioni. Tuttavia, le
sostituzioni potrebbero non essere consistenti tra loro; si osservi il seguente esempio:
\[ \tau = M \; k \; k, \; \tau' = M \; a \; b \]
dove $ M $ è un tipo concreto, mentre gli altri termini sono tutti variabili di tipo. Effettuando un'azione di
\textit{decompose}, si ottengono le seguenti sostituzioni:
\[ S_1 = \{k \mapsto a\}, \; S_2 = \{k \mapsto b\} \]
\`E chiaro che $ S_1 $ e $ S_2 $ non sono consistenti. In questi casi, \texttt{unifyOnArgs}, invece di ritornare
l'errore \texttt{UnmatchTypes}, ritorna \texttt{TrySwap}. La semantica di quest'ultimo indica che è necessario effettuare
un'azione di \textit{swap} e riprovare con \textit{decompose}. Continuando con l'esempio precedente, otterremo:
\[ S_1 = \{a \mapsto k\}, \; S_2 = \{b \mapsto k\} \]
In questo caso, $ S_1 $ e $ S_2 $ possono essere unite in un'unica sostituzione:
\[ S = \{ a \mapsto k, \; b \mapsto k \} \]
In generale, se anche il "secondo tentativo" non va a buon fine, l'algoritmo termina con un errore. La funzione che
implementa questa parte è \texttt{twoChancesUnifyArgs}. Chiaramente, come si può notare dall'implementazione di
\texttt{argsUnification}, se l'unificazione è \textit{strict}, allora il "secondo tentativo" non può essere effettuato,
in quanto vi è prima un'azione di \textit{swap} che dovrebbe essere eseguita.

\paragraph{Inferenza di lambda astrazione}
La seguente regola inferisce il tipo del costrutto di lambda-astrazione:
\[ \infer[\textbf{Abs}]{\Gamma \vdash_W \lambda x. e : S\tau \mapsto \tau', S}{\tau = newvar & \Gamma, \; x : \tau \vdash_W e : \tau', \; S} \]
Nell'inferenza di questo costrutto, l'argomento $ x $ ha come tipo una nuova variabile di tipo, alla quale viene
successivamente applicata la sostituzione derivante dall'inferenza dell'espressione $ e $.

\paragraph{Inferenza del costrutto "let..in"}
Prima di presentare la regola di inferenza, è necessario introdurre la regola di generalizzazione:
\[ \infer[\textbf{Gen}]{\Gamma \vdash_W e : \forall \alpha. \; \tau}{\Gamma \vdash_W e : \tau & \alpha \notin free(\Gamma)} \]
Questa regola quantifica le variabili di tipo che non compaiono già come variabili libere nell'ambiente di tipizzazione.
Per il costrutto \textit{let..in}, per indicare la generalizzazione, utilizzeremo la seguente notazione:
\[ \overline{\Gamma}(\tau) = \forall \overline{\alpha}. \; \tau \qquad \overline{\alpha} = free(\tau) - free(\Gamma) \]
Ora possiamo presentare la regola di inferenza del costrutto \textit{let..in}:
\[ \infer[\textbf{Let}]{\Gamma \vdash_W let \; x = e_0 \; in \; e_1 : \tau', \; S_1S_0}{\Gamma \vdash_W e_0 : \tau, \; S_0 & S_0\Gamma, x : \overline{S_0\Gamma}(\tau) \vdash_W e_1 : \tau', \; S_1} \]
\`E doveroso spiegare il motivo dell'esistenza del costrutto \textit{let..in}. Osserviamo il seguente esempio di
programma scritto nel formalismo del lambda-calcolo polimorfico:
\[ (\lambda id. \; (id \; True, id \; 42)) (\lambda x. \; x) \]
un tale programma non può essere tipato, in quanto il tipo della variabile \textit{id} non è polimorfo. Si ricordi,
infatti, che nel costrutto della lambda-astrazione, il tipo dell'argomento è un mono-tipo. Per questo motivo, è
necessario il costrutto \textit{let..in}:
\[ let \; id = \lambda x. \; x \; in \; (id \; True, id \; 42) \]
infatti, il programma appena mostrato è \textit{ben tipato}, in quanto il tipo di \textit{id} è uno schema di tipo.

\subsubsection{Implementazione delle regole di inferenza}
Il codice sorgente che implementa le regole di inferenza (e quindi la type-inference) è situato nel modulo
\texttt{Compiler.Types.Builder.Type}. Alcuni costrutti di langgg si ispirano a quelli del formalismo \textit{System-F},
tuttavia, molti vengono estesi con sintassi differenti. Ad esempio, prendendo come riferimento la definizione del token
dell'AST che rappresenta il costrutto di lambda-astrazione:
\begin{lstlisting}
newtype Lambda a = Lambda ([SymbolName a], Expression a, a)
\end{lstlisting}
si può notare come non vi sia un unico argomento, bensì, una lista. Stessa argomentazione vale per l'applicazione
di espressioni:
\begin{lstlisting}
newtype AppExpression a = AppExpr (Expression a, [Expression a], a)
\end{lstlisting}
Con le dovute accortezze, l'algoritmo di inferenza considera questi costrutti come l'equivalente di costrutti
concatenati in \textit{System-F}. Ad esempio:
\[ \texttt{lam x y z -> x + y + z} \equiv \lambda x. \; \lambda y. \; \lambda z. \; x + y + z \]

Un altra nota è necessaria sulle definizioni di simboli in langgg. Infatti, langgg permette la definizione di simboli
globali e questo "rompe" la regola di inferenza del costrutto \textit{let..in}. Questo problema viene risolto
considerando soltanto parte delle premesse del costrutto \textit{let..in}. Ad esempio:
\begin{lstlisting}
let x = e
\end{lstlisting}
come prima azione, viene inferito il tipo di \texttt{e}, sia esso il mono-tipo $ \tau $, poi viene effettuata la
generalizzazione, quindi $ x $ avrà tipo $ \forall \overline{\alpha}. \; \tau $. A questo punto, non è necessario
compiere altre azioni e il binding $ x : \forall \overline{\alpha}. \; \tau $ può essere aggiunto nell'ambiente di
tipizzazione.

Il costrutto \textit{let..in} in langgg ha nella sintassi un'altra estensione rispetto al suo omonimo in \textit{System-F},
ovvero i bindings accettano anche argomenti:
\begin{lstlisting}
let f x y = (x, y)
\end{lstlisting}
In questo caso, la politica dell'algoritmo di inferenza è trattare gli argomenti \texttt{x} e \texttt{y} come argomenti
di un costrutto di lambda-astrazione (cfr. Lambda-astrazione), quindi, si può pensare a questa equivalenza in termini
di type-inference con \textit{System-F}:
\[ \texttt{let f x y = (x, y)} \equiv let \; f = \lambda x. \; \lambda y. \; (x, y) \]

\subsubsection{Estensioni dell'algoritmo di inferenza}
langgg possiede numerosi costrutti che arricchiscono la sintassi di base di \textit{System-F}, inoltre, introduce
concetti nuovi come i predicati o i tipi qualificati. Di conseguenza, l'algoritmo di inferenza di tipo di \textit{System-F}
deve essere esteso.

\paragraph{Pattern matching}
langgg possiede due costrutti diversi per il pattern matching (cfr. Caratteristiche del linguaggio). Il primo costrutto
permette "ispezionare" il valore di una singola espressione, per esempio:
\begin{lstlisting}
type Maybe a = Nothing | Just a

val f : List a -> String
let f l =
    match first l with
          Nothing -> "Error_404"
        | Just _ -> "Ok_200"
\end{lstlisting}
Il secondo costrutto, invece, non agisce su un'espressione, ma sugli argomenti di altri costrutti, per esempio:
\begin{lstlisting}
val f : Maybe a -> b -> String
let f
    | Nothing _ -> "Error_404"
    | (Just _) _ -> "Ok_200"
\end{lstlisting}
In qualsiasi caso, vi sono sempre uno o più valori da ispezionare, uno o più casi, i quali hanno uno o più \textit{case
expressions} (nel codice, spesso vengono nominate come \textit{matching expressions}) e un'espressione di ritorno.
Quindi abbiamo un costrutto della forma:
\[ match \; val_1 \; ... \; val_n \; with \; case_1 \; ... \; case_m \]
dove $ val_i $ è un token che definiremo come \textit{token top-level} o \textit{token di scrutinio} e
$ case_j $, che chiameremo \textit{caso}, ha la forma:
\[ me_{1j}, \; ... \; me_{nj} \rightarrow e_j \]
L'algoritmo di inferenza di tale costrutto è il seguente:
\begin{itemize}
    \item Inferisci $ val_i $, applica le sostituzioni all'ambiente di tipizzazione e poi fai lo stesso con $ val_{i+1} $,
    finché non termina la lista di token di scrutinio;
    \item nell'inferenza dei casi, dovrà valere:
        \[ \forall j. \; typeOf(val_i) \sqsubseteq typeOf(me_{ij}) \]
    ovvero le case expressions non potranno avere un tipo più generale dei corrispondenti token di scrutinio;
    \item nell'inferenza dei casi, è necessario tener traccia dei tipi dei casi già inferiti in precedenza, in
    quanto non sempre dai casi precedenti si inferisce il tipo più specializzato tra tutti i casi $ case_j $, quindi,
    i casi già inferiti verrano mantenuti;
    \item inferisci $ case_j $, applica le sostituzioni all'ambiente di tipizzazione e ai casi precedenti, poi passa
    a $ case_{j+1} $;
    \begin{itemize}
        \item nell'inferenza del caso j-esimo, il quale avrà la forma $ me_{1j} \; ... \; me_{nj} \rightarrow e_j $,
        verranno inferite, una alla volta, le case expressions $ me_{ij} $;
        \item inferisci come se fosse un argomento di una lambda astrazione $ me_{ij} $ la quale avrà mono-tipo $ \tau $,
        trova il tipo dell'i-esima case expression nei casi precedenti, sia esso $ \tau' $, poi effettua
        l'unificazione tra $ \tau $ e $ \tau' $ e applica le sostituzioni
        all'ambiente di tipizzazione e ai casi precedenti, poi continua con $ me_{i+1j} $ finché non termina la lista di
        case expressions;
        \item inferisci $ e_j $, la quale avrà mono-tipo $ \tau $, trova il tipo delle espressioni dei casi, sia esso
        $ \tau' $, effettua l'unificazione tra $ \tau $ e $ \tau' $ e applica le sostituzioni all'ambiente di tipizzazione
        e ai casi precedenti.
    \end{itemize}
\end{itemize}

\paragraph{Constraints}
%TODO

\paragraph{Type-hinting}
langgg permette all'utente di indicare il tipo di un'espressione (o di un simbolo). Questo comporta una modifica
all'algoritmo di inferenza di tipo. Data un'espressione con type-hinting, lo schema generale è inferire prima
l'espressione e successivamente "applicare" il type-hinting. Per quanto riguarda i casi ricorsivi delle espressioni
(tutti i casi fuorché i simboli, i letterali e i data-constructors), il tipo proveniente dal type-hinting viene
"scomposto" in più sotto-tipi che vengono utilizzati come type-hinting nell'inferenza dei casi ricorsivi. Tale
scomposizione è definita sui tipi funzione ed è chiamata, all'interno del codice sorgente, operazione di
\textit{unfold}:
\begin{lstlisting}
unfoldType(ty):
    match ty with
        (ty1 -> ty2) -> ty1 : unfoldType ty2
        _ -> [ty]
\end{lstlisting}
Questa operazione è molto utile, ad esempio, nell'inferenza della lambda astrazione. Si osservi il seguente sorgente
langgg:
\begin{lstlisting}
(lam x -> f x) : Char -> String
\end{lstlisting}
Il tipo \texttt{Char -> String} viene scomposto in \texttt{Char} e \texttt{String}. Nell'inferenza dell'argomento
\texttt{x}, il type-hinting sarà esattamente \texttt{Char}, mentre per l'inferenza dell'espressione \texttt{f x}
il type-hinting sarà \texttt{String}.

Per quanto riguarda, invece, i casi di base, lo schema è:
\begin{itemize}
    \item cerca nell'ambiente di tipizzazione il tipo del token, sia esso lo schema di tipo $ \sigma $;
    \item applica la regola di istanziazione su $ \sigma $, sia $ \tau $ il mono-tipo risultante;
    \item sia $ \pi $ il mono-tipo istanziato dallo schema di tipo proveniente dal type-hinting;
    \item effettua l'unificazione \textit{strict} tra $ \pi $ e $ \tau $; si ricordi che tale operazione, a differenza
    dell'unificazione originale, non gode della proprietà commutativa, in quanto l'azione di \textit{swap} non è
    ammessa. Il mono-tipo $ \pi $ non può essere modificato dopo la sostituzione;
    \item applica l'unificazione all'ambiente di tipizzazione e al token tipato.
\end{itemize}
La regola è molto simile a quella senza type-hinting, tuttavia, viene effettuata un'unificazione in più.
Dato che l'insieme dei letterali e dei data-constructors all'interno del linguaggio non può avere variabili libere,
un'ottimizzazione che viene applicata ai loro casi è non applicare la sostituzione
all'ambiente di tipizzazione. Un'operazione che, in generale, è piuttosto dispendiosa.

\paragraph{Funzioni ricorsive}
%TODO

\section{Generazione del codice}
L'output dell'algoritmo di type inference è un \texttt{TypedProgram}, una tabella che mantiene i bindings tipati.
La generazione del codice consiste in tre sotto-fasi:
\begin{enumerate}
    \item alcuni task che riguardano il desugaring, necessari per la generazione del codice;
    \item traduzione dai token tipati di \texttt{Compiler.Ast.Typed} ai token della sintassi del linguaggio Core;
    \item esecuzione del backend di Haskell, il quale genera il codice a basso livello di target differenti.
\end{enumerate}
Di seguito, lo schema delle fasi finali del compilatore:
\newline

\begin{tikzpicture}[node distance=2cm]
\node (typedProg) [object] {Bindings tipati};
\node (staticDispatch) [object, below of=typedProg] {Bindings tipati};
\draw [arrow] (typedProg) -- node[anchor=east] {Dispatch statico} (staticDispatch);
\node (lambdas) [object, below of=staticDispatch] {Bindings tipati};
\draw [arrow] (staticDispatch) -- node[anchor=east] {Lambda-astrazione} (lambdas);
\node (deepPm) [object, below of=lambdas] {Bindings tipati};
\draw [arrow] (lambdas) -- node[anchor=east] {Rimozione del pattern matching "profondo"} (deepPm);
\node (scrutinee) [object, below of=deepPm] {Bindings tipati};
\draw [arrow] (deepPm) -- node[anchor=east] {Unificazione degli scrutini} (scrutinee);
\node (coreGen) [object, below of=scrutinee] {Sintassi Core};
\draw [arrow] (scrutinee) -- node[anchor=east] {Generazione della sintassi Core} (coreGen);
\node (backend) [object, below of=coreGen] {Codice finale};
\draw [arrow] (coreGen) -- node[anchor=east] {Backend Haskell} (backend);
\node (desugar) [object, right of=lambdas, xshift=4cm] {Desugaring};
\draw [arrow] (desugar) -- (staticDispatch);
\draw [arrow] (desugar) -- (lambdas);
\draw [arrow] (desugar) -- (deepPm);
\draw [arrow] (desugar) -- (scrutinee);
\end{tikzpicture}

\subsection{Dispatch statico}
Il polimorfismo ad-hoc viene implementato attraverso il meccanismo delle type-classes (cfr. Polimorfismo ad-hoc).
La sintassi Core non possiede, però, costrutti per i metodi delle type-classes e per i bindings delle istanze.
La politica del compilatore langgg è quella di aggiungere i bindings delle istanze ai bindings del programma,
cambiando i nomi degli stessi metodi di istanze diverse (cfr. Costruzione delle istanze). Questa politica ha
importanti implicazioni: innanzitutto, nelle espressioni del programma, i metodi delle istanze possono essere chiamati,
ma essi possono essere nominati solamente tramite gli identificatori dei metodi delle proprietà. Ad esempio:
\begin{lstlisting}
property Foo a =
    val foo : a -> a
;;

instance Foo String =
    let foo s = s
;;

let f x = (x, foo "42")
\end{lstlisting}
Come è stato già esposto in precedenza, il metodo \texttt{foo} dell'istanza \texttt{Foo Int} avrà un identificatore
diverso da \texttt{foo}. Tuttavia, \texttt{foo} viene nominato nell'espressione legata a \texttt{f}. \`E necessario,
quindi, un modo per trasformare, eventualmente, le occorrenze dei metodi di proprietà con i giusti metodi di istanza.
Si pensi a quest'altro pezzo di codice langgg:
\begin{lstlisting}
type Box a = Box a

val g : Foo (Box a) => a -> Box a
let g x = foo (Box x)

let h v = g v
\end{lstlisting}
\`E chiaro come la chiamata di \texttt{foo} all'interno dell'espressione legata a \texttt{g} dipenda da quale istanza
della forma \texttt{Foo (Box a)} venga utilizzata. Vale lo stesso per \texttt{g} nei confronti dell'espressione legata
ad \texttt{h}. In linea generale, il suddetto problema è legato al polimorfismo ad-hoc e viene risolto attraverso un
metodo di dispatch statico. Il polimorfismo ad-hoc permette di creare funzioni che hanno comportamenti diversi a
seconda del loro tipo. Il dispatch statico si occupa di "scegliere" correttamente le funzioni a disposizione nel
programma (i metodi d'istanza) che implementano i relativi metodi di proprietà nel programma. A differenza di molti
linguaggi object-oriented, in cui la selezione dei metodi avviene a run-time attraverso meccanismi di dispatch dinamici,
in langgg la selezione viene risolta completamente a compile-time, evitando così l'overhead che può essere causato
da un algortimo di dispatch dinamico. In particolare, il dispatch statico in langgg viene implementato attraverso
la \textit{monomorfizzazione} [11], già introdotta, in realtà, nella costruzione delle istanze. Ora renderemo la
monomorfizzazione generale a tutte le funzioni del programma; l'implementazione che seguirà è ispirata da un articolo
sul blog di Jeremy Mikkola [12]. Si ripensi alla precedente funzione \texttt{g}. Il suo
schema di tipo ha con sè dei predicati. In questo caso, durante la fase di type-inference, alla funzione \texttt{g}
verrà aggiunto un parametro che corrisponderà al predicato \texttt{Foo (Box a)}, ovvero stiamo trattando il tipo di
\texttt{g} come se fosse:
\begin{lstlisting}
val g : Foo (Box a) -> a -> Box a
\end{lstlisting}
\`E necessario estendere la definizione di tipo qualificato:
\[ QT := MT \; | \; C \; | \; C \Rightarrow QT \]
Quindi, un tipo qualificato in langgg può possedere soltanto constraints. Questa eventualità viene tuttavia limitata
a pochi casi possibili e, comunque, langgg non espone una sintassi per esprimere tipi qualificati che possiedono
soltanto constraints.

\subsection{Lambda-astrazione}

\section*{Bibliografia}
\begin{enumerate}[label={[\arabic*]}]
    %[1]
    \item Amr Sabry - What is a purely functional language? - in: Journal of Functional Programming, Volume 8, Issue 1,
    January 1998, pp. 1 - 22
    %[2]
    \item Martin Sulzmann, Martin Odersky, Martin Wehr - Type Inference with Constrained Types - in: Theory and Practice
    of Object Systems · January 1999
    %[3]
    \item Stephen Diehl - Dive into GHC: Targeting Core - url: \url{https://www.stephendiehl.com/posts/ghc_03.html}
    %[4]
    \item libreria Parsec - url: \url{https://hackage.haskell.org/package/parsec}
    %[5]
    \item Data types for Haskell entities - url:
    \url{https://gitlab.haskell.org/ghc/ghc/-/wikis/commentary/compiler/entity-types}
    %[6]
    \item Edward Y. Zang - Backpack without symbol tables - in: May 11, 2016 - url:
    \url{http://web.mit.edu/~ezyang/Public/backpack-symbol-tables.pdf}
    %[7]
    \item Haskell Flexible Instances extension - url:
    \url{https://ghc.gitlab.haskell.org/ghc/doc/users_guide/exts/instances.html#extension-FlexibleInstances}
    %[8]
    \item Haskell instance resolution termination conditions - url:
    \url{https://ghc.gitlab.haskell.org/ghc/doc/users_guide/exts/instances.html#instance-termination-rules}
    %[9]
    \item Martin Sulzmann, Gregory J. Duck, Simon Peyton-Jones, Peter J. Stuckey - Understanding Functional Dependencies
    via Constraint Handling Rules - in: Journal of Functional Programming, Volume 17, Issue 1, January 2007, pp. 83 - 129
    %[10]
    \item Definizione di ClsInst in GHC - url: \url{https://hackage.haskell.org/package/ghc-8.10.7/docs/src/InstEnv.html#ClsInst}
    %[11]
    \item Monomorphization - url: \url{https://doc.rust-lang.org/book/ch10-01-syntax.html#performance-of-code-using-generics}
    %[12]
    \item Type inference for Haskell, part 15 - url: \url{https://jeremymikkola.com/posts/2019_01_15_type_inference_for_haskell_part_15.html}
\end{enumerate}

\end{document}
