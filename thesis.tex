\documentclass[10pt,a4paper]{article}
\usepackage[italian]{babel}
\usepackage{newlfont}
\usepackage{listings}
\usepackage{tikz}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{proof}

\lstset{
    language=Haskell,
    basicstyle={\small\ttfamily}
}

\tikzstyle{process} =
    [rectangle, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=white!30]
\tikzstyle{object} =
    [rectangle, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=white!30]
\tikzstyle{arrow} = [thick,->,>=stealth]

\textwidth=450pt\oddsidemargin=0pt

\begin{document}
\begin{titlepage}

\begin{center}

{{\Large {\textsc {Alma Mater Studiorum $\cdot$ Universit\`a di Bologna}}}} \rule[0.1cm]{15.8cm}{0.1mm}

\rule[0.5cm]{15.8cm}{0.6mm}
{\small {\bf SCUOLA DI SCIENZE\\
Corso di Laurea in Nome corso di Laurea }}

\end{center}

\vspace{15mm}
\begin{center}

{\LARGE
    {\bf COMPILATORE PER LINGUAGGIO DI}
}\\
\vspace{3mm}
{\LARGE
    {\bf PROGRAMMAZIONE FUNZIONALE}
}\\
\vspace{3mm}
{\LARGE
    {\bf SPERIMENTALE}
}\\

\end{center}

\vspace{40mm}
\par
\noindent
\begin{minipage}[t]{0.47\textwidth}

{\large
    {\bf Relatore:\\
        Chiar.mo Prof.\\
        CLAUDIO SACERDOTI COEN
    }
}

\end{minipage}

\hfill
\begin{minipage}[t] {0.47\textwidth}\raggedleft
{\large
    {\bf Presentata da:\\
        LUCA BORGHI
    }
}

\end{minipage}

\vspace{20mm}
\begin{center}

{\large
    {\bf Sessione\\
        III sessione
        2021-2022
    }
}%2018-2019

\end{center}

\end{titlepage}

\textwidth=450pt\oddsidemargin=0pt

\section{Introduzione}

%TODO: dove viene descritto il problema, la subsection può essere rimossa
\subsection{Il linguaggio}

\subsection{Haskell come modello}
Il compilatore è stato sviluppato mediante il linguaggio \textit{Haskell}, anch'esso linguaggio di programmazione funzionale.
Inoltre, il linguaggio target di langgg è \textit{Core}, un formalismo fortemente basato su \textit{System F}, una
variante tipata del lambda-calcolo che introduce un meccanismo di quantificazione universale sui tipi. Core, inoltre,
viene utilizzato da GHC (compilatore Haskell) come rappresentazione intermedia di Haskell. All'interno di questo
contesto, GHC espone delle API che permettono al cliente di utilizzare le funzionalità del compilatore (cfr. [2]); è quindi
possibile creare e manipolare programmi Core mediante le API, le quali sono state scritte in Haskell. Per quest'ultimo
motivo, Haskell è stato scelto come linguaggio di implementazione del compilatore di langgg, tuttavia, nel contesto
del progetto, Haskell ha anche un altro importante ruolo: alcune delle sue funzionalità sono state, direttamente
o indirettamente, fonte di ispirazione per il design di langgg. Nel prossimo paragrafo vengono presentate le principali
caratteristiche di langgg ed è possibile ritrovare la maggior parte di esse anche in Haskell. Un altro linguaggio
che è stato fonte di ispirazione, ma con minore impatto, è \textit{OCaml}, linguaggio multi-paradigma (funzionale non
puro), soprattutto per la sintassi di langgg e per il costrutto delle polymorphic variants (cfr. paragrafo sugli
sviluppi futuri).

\subsection{Caratteristiche del linguaggio}
Tra le principali caratteristiche del linguaggio vi sono:
\begin{description}
\item[Linguaggio funzionale puro] Come Haskell, langgg è un linguaggio funzionale puro. La nozione di linguaggio
di programmazione \textit{funzionale} è piuttosto lasca e non vi è una vera e propria definizione formale,
tant'è che il termine viene spesso utilizzato (e, talvolta, abusato) per indicare un linguaggio avente alcune
particolari specifiche attribuibili al paradigma di programmazione funzionale. langgg può essere quindi considerato
funzionale poiché, semplicemente, ha numerose caratteristiche proprie del paradigma funzionale, quali: tipi di dati
algebrici, pattern matching, funzioni di ordine superiore, immutabilità, polimorfismo parametrico etc.. Per quanto
riguarda la nozione di \textit{purità}, nel paradigma funzionale viene fatta spesso la distinzione
tra linguaggi puri e impuri; anche qui, non vi sono vere e proprie definizioni e la questione è spesso oggetto di
controversie. Una proposta di definizione è stata fornita da Amr Sabry in [1]: la purità ha a che fare con il passaggio
dei parametri, in particolare, un linguaggio L può essere
considerato puro se, dato un qualsiasi programma p scritto in L, le funzioni di p sono dei "\textit{mapping}" puri
dai valori in input ai valori in output, indipendentemente dal tipo di passaggio dei parametri.
\item[Type-system statico con type-inference] langgg è un linguaggio con type-system statico, inoltre, la fase di
type-checking garantisce la proprietà di type-safety. Il linguaggio permette anche di omettere le indicazioni di
tipo (type-hinting) nella definizione di simboli; in caso non vi sia type-hinting per la definizione di un simbolo,
il compilatore inferirà il tipo "più generale possibile" per il simbolo.
\item["Everything is an expression"] tutti i costrutti all'interno di langgg possono essere considerati espressioni
prive di side-effects; non vi sono costrutti di controllo o costrutti che modificano variabili di stato esterne
al contesto locale. I costrutti principali sono:
    \begin{enumerate}
    \item definizioni di: tipi, variabili, proprietà (che corrispondono alle type-classes di Haskell), istanze di
    proprietà, alias di tipi, firme di simboli; le definizioni di simboli hanno le seguenti grammatiche:
    \begin{lstlisting}
      S :=
          let var args = E

     MS :=
          let var MPM
    \end{lstlisting}
    \item espressioni date dalla seguente grammatica:
    \begin{lstlisting}
      E :=
          var
          datacon
          literal
          E E
          lam args -> E
          lam MPM
          S in E
          MS in E
          match E with PM

     PM :=
          ME -> E | ... | ME -> E

    MPM :=
          | ME ... ME = E | ... | ME ... ME = E

     ME :=
          var
          _
          literal
          datacon ME ... ME
          
    \end{lstlisting}
    \item un costrutto, valutato a compile-time (cfr. parsing degli operatori), per definire una "categoria" di
    operatori. Le categorie di operatori hanno degli identificatori per poterle nominare, inoltre definiscono le
    seguenti proprietà:
        \begin{enumerate}
        \item una lista di operatori appartenenti alla proprietà. Sono compresi gli identificatori di variabili (gli
        operatori stessi sono identificatori di variabili) che possono essere utilizzati con la sintassi degli operatori;
        \item una lista di categorie di operatori i quali avranno meno precedenza degli operatori della categoria
        corrente;
        \item una lista di categorie di operatori i quali avranno più precedenza degli operatori della categoria
        corrente;
        \item la fissità degli operatori.
        \end{enumerate}
    \end{enumerate}
\item[Tipi di dati algebrici] langgg supporta anche i tipi di dati algebrici (che sono l'unico modo per definire nuovi
tipi). Con essi, vi è anche la nozione di \textit{data constructor}, ovvero un costrutto dotato di tipo che può essere
accompagnato da dati. Per eseguire operazioni con i tipi di dati algebrici vi è il costrutto del pattern matching
(cfr. grammatica delle espressioni) che permette di destrutturare un data constructor dai suoi dati associati.
\item[Polimorfismo parametrico] il sistema di tipi del linguaggio supporta le variabili di tipo. Questo tipo di
polimorfismo permette di avere singoli algoritmi per una moltitudine di tipi.
\item[Kind] Il linguaggio permette la manipolazione di \textit{funzioni di tipi}, introducendo la nozione di
\textit{kind} (cfr. sezione sul sistema di tipi). Quindi, data la seguente definizione di tipo:
\begin{lstlisting}
type M a b = DataCon1 a | DataCon2 b | DataCon3 a Char
\end{lstlisting}
dove \textit{a} e \textit{b} sono variabili di tipo, è possibile, ad esempio, avere tipi della forma:
\begin{lstlisting}
M Int Char
M a b
M String
M x
M
\end{lstlisting}
\`E possibile altresì avere un tipo della forma:
\begin{lstlisting}
m Int
\end{lstlisting}
dove \textit{m} è una variabile di tipo a cui viene applicata il tipo \textit{Int}.
\item[Polimorfismo ad hoc] attraverso il meccanismo delle type-classes (all'interno del linguaggio vengono chiamate
proprietà), è possibile creare funzioni polimorfe che possono essere applicate ad argomenti di tipi differenti e, a
seconda dei tipi degli argomenti, viene "selezionata" la giusta implementazione. Ogni proprietà può avere uno, ma anche
più tipi associati; inoltre, i tipi associati alle proprietà possono essere anche variabili di tipo.

\end{description}

\section{Il compilatore}

\subsection{La struttura}
\begin{tikzpicture}[node distance=2cm]
\node (src) [object] {Codice sorgente};
\node (parser) [process, below of=src] {Parser};
\draw [arrow] (src) -- (parser);
\node (checker) [process, below of=parser] {Checker della correttezza};
\draw [arrow] (parser) -- (checker);
\node (typedBuilder) [process, below of=checker] {Costruzione dei token tipati};
\draw [arrow] (checker) -- (typedBuilder);
\node (prepare) [process, below of=typedBuilder] {Preparazione alla type inference};
\draw [arrow] (typedBuilder) -- (prepare);
\node (typeInf) [process, below of=prepare] {Type inference - type checking};
\draw [arrow] (prepare) -- (typeInf);
\node (CoreGen) [process, below of=typeInf] {Generazione codice Core};
\draw [arrow] (typeInf) -- (CoreGen);
\node (backend) [process, below of=CoreGen] {Backend};
\draw [arrow] (CoreGen) -- (backend);
\node (exe) [process, below of=backend] {Eseguibile};
\draw [arrow] (backend) -- (exe);
\node (desugar) [process, right of=prepare, xshift=7cm] {Desugaring};
\draw [arrow] (desugar) -- (checker);
\draw [arrow] (desugar) -- (typedBuilder);
\draw [arrow] (desugar) -- (prepare);
\draw [arrow] (desugar) -- (typeInf);
\draw [arrow] (desugar) -- (CoreGen);
\end{tikzpicture}

La struttura del compilatore è sequenziale, con eccezione fatta per la fase di \textit{desugaring}. Quest'ultima si
occupa di rimuovere il cosiddetto "zucchero sintattico" dalle strutture dati - che mantengono le informazioni del
programma - che, durante le varie fasi di compilazione, possono subire semplificazioni. Talvolta, alcune semplificazioni
vengono posticipate il più possibile per permettere al compilatore di restituire in output messaggi d'errore comprensibili
per l'utente. Un esempio ne è la trasformazione che subiscono le strutture dati che rappresentano il costrutto del
pattern matching. Il modulo che si occupa del desugaring si presenta come una libreria che espone delle API che agiscono
sulle strutture dati del compilatore. \`E compito del compilatore fare le chiamate al modulo di desugaring. Di seguito,
vi è una più ampia e precisa descrizione delle singole fasi di compilazione, con enfasi particolare sugli algoritmi
più interessanti utilizzati per risolvere i singoli sottoproblemi e su come le varie fasi interagiscono tra loro.

\section{L'albero di sintassi astratta}
Nella prima parte del compilatore viene eseguito il parsing del sorgente.
Questa operazione produce quindi l'albero di sintassi astratta (AST). Il codice che gestisce i "token" dell'AST è
all'interno del modulo \texttt{Compiler.Ast.Tree}; l'entry point dell'albero è dato dal token \texttt{Program}, il
quale, come nodi figli, ha delle \texttt{Declaration} che rappresentano i vari costrutti del linguaggio.

\begin{lstlisting}
newtype Program a = Program [Declaration a]

data Declaration a =
      ADT (AlgebraicDataType a)
    | AliasADT (AliasAlgebraicDataType a)
    | Intf (Interface a)
    | Ins (Instance a)
    | Sig (Signature a)
    | Let (SymbolDeclaration a)
    | LetMulti (MultiSymbolDeclaration a)
\end{lstlisting}

Di seguito vi è lo schema della prima parte del compilatore:

\begin{tikzpicture}[node distance=2cm]
\node (src) [object] {Codice sorgente};
\node (rawast) [object, below of=src] {Albero di sintassi astratta};
\draw [arrow] (src) -- node[anchor=west] {Parser} (rawast);
\node (rawastBuiltin) [object, below of=rawast] {Albero di sintassi astratta};
\draw [arrow] (rawast) -- node[anchor=west] {Aggiunta token built-in} (rawastBuiltin);
\node (rawastNames) [object, below of=rawastBuiltin] {Albero di sintassi astratta};
\draw [arrow] (rawastBuiltin) -- node[anchor=west] {Check esistenza dei nomi} (rawastNames);
\node (rawastArgs) [object, below of=rawastNames] {Albero di sintassi astratta};
\draw [arrow] (rawastNames) -- node[anchor=west] {Check numero degli argomenti} (rawastArgs);
\node (rawastAlias) [object, below of=rawastArgs] {Albero di sintassi astratta};
\draw [arrow] (rawastArgs) -- node[anchor=west] {Sostituzione degli alias di tipo} (rawastAlias);
\node (desugar) [object, right of=rawastAlias, xshift=7cm] {Desugaring};
\draw [arrow] (desugar) -- (rawastAlias);
\end{tikzpicture}

\subsection{Il parser}
Il parser è la prima componente del compilatore (dopo la lettura del sorgente). \`E stato scritto mediante la libreria
open-source \texttt{Parsec} [4], la quale si basa sul concetto di parser combinator monadico. Il codice risiede nel
modulo \texttt{Compiler.Syntax} ed ha una struttura gerarchica: parte definendo i combinators di "pezzi" primitivi dei
token dell'AST (\texttt{Compiler.Syntax.Lib.SimpleParser}), dopodiché, nel modulo \texttt{Compiler.Syntax.Grammar} vi
è la generazione vera e propria dei token dell'AST e, infine, vi è l'entry point del parser, ovvero
\texttt{Compiler.Syntax.Parser}. \`E bene notare che all'interno del modulo \texttt{Compiler.Syntax.Lib.SimpleParser}
non sono visibili le API dell'AST, in quanto esso si occupa soltanto del parsing dei costrutti del linguaggio e non
della generazione dei token.

\subsubsection{Parsing degli operatori}
langgg permette di definire operatori che vengono trattati come simboli di variabili (funzioni). In questo contesto,
il linguaggio espone all'utente un costrutto particolare che permettere di definire le proprietà degli eventuali
operatori. Questo costrutto viene valutato durante il parsing e definisce una categoria di operatori, ecco un esempio:

\begin{lstlisting}
OPERATORS_CATEGORY {#
    name : Application ;
    operators : |>, <|, `applyTo ;
    lesser than : Comparison, Numeric ;
    greater than : Functor ;
    fixity : InfixLeft ;
#}
\end{lstlisting}

Il primo "campo" è il nome della categoria ed è utile per poter identificare la categoria, infatti, il terzo e il
quarto campo definiscono rispetto a quali categorie gli attuali operatori hanno precedenza. Il secondo campo definisce
l'insieme di operatori che fanno parte della categoria. Infine, l'ultimo campo è una costante e definisce la fissità
degli operatori: infissa senza associazione, infissa con associazione a sinistra, infissa con associazione a destra,
postfissa o prefissa. La versione infissa è solo per gli operatori binari, mentre postfissa e prefissa solo per gli
operatori unari. Si può notare che nella lista di operatori vi è anche un simbolo di variabile preceduto dal simbolo
di backtick; questo è possibile, in quanto langgg permette di utilizzare i simboli di variabili come operatori
facendoli precedere dal carattere backtick. La valutazione di questo costrutto è interamente integrata nel parser ed
è obbligatorio per l'utente definire le categorie degli operatori all'inizio del sorgente. La libreria \texttt{Parsec}
offre delle API anche per il parsing degli operatori; l'algoritmo di gestione delle categorie si occupa di costruire
una tabella di operatori, implementata semplicemente come una lista di liste, ordinando i gruppi (di categorie) in
base alla loro precedenza. Le informazioni sulle categorie vengono estrapolate dal parsing del costrutto e vengono
passate successivamente all'algoritmo di ordinamento delle categorie. Quest'ultimo si può ridurre all'inserimento
di un elemento in una lista di liste:

\begin{lstlisting}
insert(x, ll):
    match ll with
        [] -> [[x]]
        (l :: lt) ->
            if any x' in l. x' < x        // Condizione d'inserimento (1)
            then
                if areAmbigous(x, ll)
                then fail
                else [x] :: l :: lt
            else if all x' in l. x' == x  // Condizione d'inserimento (2)
            then
                if areAmbigous(x,ll)
                then fail
                else subInsert(x, l) :: lt
            else l :: insert(x, lt)
\end{lstlisting}

L'algoritmo scorre la lista finché non:
\begin{enumerate}
    \item trova una sottolista \textit{l} in cui esiste almeno un elemento minore di \textit{x}; in questo caso, controlla
    eventuali ambiguità delle categorie, poiché l'utente potrebbe aver definito categorie tali che la nozione di
    ordinamento tra loro non è transitiva. La funzione \texttt{areAmbigous} nel pezzo di pseudocodice si occupa
    di eseguire questo controllo. Se non esistono ambiguità tra le categorie, allora viene creata una nuova lista
    singoletto contenente \textit{x} che viene inserita davanti alla sottolista \textit{l}
    \item trova una sottolista \textit{l} in cui tutti gli elementi sono uguali a \textit{x}; in questo caso, \textit{x}
    viene inserito in \textit{l}, eseguendo sempre prima il controllo sulle ambiguità.
\end{enumerate}
In tutti gli altri casi, la corrente sottolista \textit{l} contiene almeno un elemento $ x' $ tale che
$ x' > x $, quindi l'inserimento non può ancora avvenire. Quando la tabella è completa, essa viene passata alla
funzione \texttt{buildExpressionParser} della libreria \texttt{Parsec} che si occupa di costruire il parser per le
espressioni.

\subsection{Check dei nomi}
Dopo la fase di parsing e dell'aggiunta di token built-in del linguaggio (ad esempio, alcuni operatori aritmetici),
viene effettuato il controllo di esistenza di ogni tipo di simbolo: nomi di tipo, nomi di variabili, nomi di proprietà,
etc.. Perciò deve valere la seguente condizione:
    \[ \forall name \in AST. \exists def(name) \]
dove \textit{def} è la funzione che ritorna la definizione di un token dell'AST.
Questo tipo di check è molto importante in quanto fasi successive del compilatore basano le loro computazioni
sull'ipotesi che tutti i simboli sono stati definiti. Il codice risiede nel modulo \texttt{Compiler.Args}.

\subsection{Check degli argomenti}
Il controllo degli argomenti viene effettuato, a differenza del check dei nomi che viene eseguito su ogni tipo di nome,
solo sui nomi di tipo, di alias e di proprietà. In particolare, devono valere le seguenti condizioni:
\[ \forall name \in AST. \]
\begin{enumerate}
    \item:
        \[ isTypeName(name) \Longrightarrow \# args(name) \leq \#args(def(name)) \]
    \item:
        \[ isAliasName(name) \Longrightarrow \#args(name) = \#args(def(name)) \]
    \item:
        \[ isPropertyName(name) \Longrightarrow \#args(name) = \#args(def(name)) \]
\end{enumerate}
dove \textit{isTypeName}, \textit{isAliasName}, \textit{isPropertyName} sono le funzioni che ritornano \textit{true}
se il nome in input è, rispettivamente, un nome di tipo, un nome di alias, un nome di proprietà, \textit{false} altrimenti,
\textit{args} è la funzione che calcola gli argomenti di un token e il simbolo \textit{\#} è la funzione che calcola
la cardinalità di un insieme. La condizione (1) è meno stringente di (2) e di (3),
in quanto l'utente può "manipolare" non solo tipi, ma anche funzioni di tipi,
anche conosciute come \textit{type constructor}. La condizione (2) è fondamentale per la prossima fase del compilatore.
Il codice risiede nel modulo \texttt{Compiler.Args}.

\subsection{Eliminazione degli alias di tipo}
langgg offre un costrutto che permette all'utente di definire alias di tipi. Ecco un esempio:

\begin{lstlisting}
alias CharAnd x = Tuple2 Char x
\end{lstlisting}

Questo tipo di costrutto viene completamente valutato in fase di compilazione: ogni occorrenza di nome di alias viene
trattata come una vera e propria macro, quindi viene sostituita con il tipo associato all'alias. Il modulo di Desugaring
si occupa di questo task (\texttt{Compiler.Desugar.Alias}).
Come si nota nell'esempio, gli alias ammettono argomenti (variabili di tipo) che vengono passati alla funzione di tipo.
Il linguaggio ammette anche alias di alias, tuttavia, ciò può portare a \textit{cicli} di alias, come ad esempio:

\begin{lstlisting}
alias A = B
alias B = C
alias C = A
\end{lstlisting}

Per questo motivo, l'algoritmo di sostituzione degli alias implementa anche la "cycle detection". Inoltre, nella
sostituzione è fondamentale che valga la condizione sugli alias nel check degli argomenti (cfr. check degli argomenti):
    \[ \forall name \in AST. isAliasName(name) \Longrightarrow \#args(name) = \#args(def(name)) \]
Se la sopracitata condizione non fosse vera, non sarebbe possibile effettuare l'unificazione nella kind-inference (cfr.
kind-inference).

\subsection{Eliminazione delle firme di funzioni}
langgg espone un costrutto, detto \textit{signature} (in italiano "firma"), che permette di indicare il tipo di un
binding. Ad esempio:

\begin{lstlisting}
val id : a -> a
\end{lstlisting}

L'esempio appena mostrato indica che la variabile \textit{id} ha tipo $ \forall \alpha. \alpha \mapsto \alpha $. Questo
tipo di costrutto non è nient'altro che "zucchero sintattico" per il type-hinting dei binding. I token dei binding
- \texttt{SymbolDeclaration} e \texttt{MultiSymbolDeclaration} - possono possedere delle informazioni sul type-hinting,
ad esempio, guardando la definizione di \texttt{MultiSymbolDeclaration}:

\begin{lstlisting}
data MultiSymbolDeclaration a =
    MultiSymTok (SymbolName a) (Hint a) (MultiPatternMatch a) a
\end{lstlisting}

si può notare che il costruttore \texttt{MultiSymTok} prenda in input un token \texttt{Hint}. Il task del modulo
\texttt{Desugar.Sigs} è di eliminare dall'AST i costrutti \texttt{Signature} che rappresentano, appunto, le firme delle
variabili e aggiungere la loro informazione sul tipo come type-hinting delle definizioni delle variabili.

\section{Generazione dei token "tipati"}
Dopo la generazione dell'albero di sintassi astratta e alcune fasi di desugaring, questa seconda macro componente del
compilatore si occupa della generazione dei token "tipati". Questi ultimi prendono questa nomea in quanto, a questo
livello, compaiono le nozioni di tipo e di kind del linguaggio.

\begin{tikzpicture}[node distance=2cm]
\node (desast) [object] {AST "dezuccherato"};
\node (desastContsCheck) [object, below of=desast] {AST "dezuccherato"};
\draw [arrow] (desast) -- node[anchor=east] {Check dei constraints} (desastContsCheck);
\node (typesTable) [object, below of=desastContsCheck] {Tabella dei tipi};
\draw [arrow] (desastContsCheck) -- node[anchor=east] {Kind-inference} (typesTable);
\node (consTable) [object, below of=typesTable] {Tabella dei costrutturi};
\draw [arrow] (typesTable) -- node[anchor=east] {Costruzione dei data constructor} (consTable);
\node (contsTable) [object, below of=consTable] {Tabella dei constraints o predicati};
\draw [arrow] (consTable) -- node[anchor=east] {Costruzione dei constraints} (contsTable);
\node (instances) [object, below of=contsTable] {Tabelle di: metodi di proprietà; metodi di istanza; istanze};
\draw [arrow] (contsTable) -- node[anchor=east] {Valutazione delle istanze di proprietà} (instances);
\node (bindings) [object, below of=instances] {Bindings dell'AST pronti per la type-inference};
\draw [arrow] (instances) -- node[anchor=east] {"Preparazione" alla type-inference} (bindings);
\node (tyBindings) [object, below of=bindings] {Bindings tipati};
\draw [arrow] (bindings) -- node[anchor=east] {type-inference} (tyBindings);
\node (desugar) [object, right of=bindings, xshift=6cm] {Desugaring};
\draw [arrow] (desugar) -- (instances);
\draw [arrow] (desugar) -- (bindings);
\draw [arrow] (desugar) -- (tyBindings);
\end{tikzpicture}

\subsection{Approccio a tabelle}
A differenza della prima macro componente del compilatore, dove l'unica struttura dati di primo livello era l'AST, in
questo caso vi sono molteplici strutture dati di primo livello. Innanzitutto, nel modulo \texttt{Compiler.Ast.Typed},
vi sono le definizioni di tutti i token tipati e le operazioni su di essi; proprio in questo modulo compaiono:
\begin{enumerate}
    \item le nozioni che riguardano i tipi del linguaggio:
    \begin{lstlisting}
data LangKind               --kind
data LangVarType a          --variabile di tipo
data LangHigherType a       --mono-tipo
data LangSpecConstraint a   --"constraint" o predicato
data LangQualType a         --mono-tipo qualificato
data LangTypeScheme a       --poli-tipo o schema di tipo
    \end{lstlisting}
    \item i token tipati che costituiscono un programma:
    \begin{lstlisting}
data NotedVar a           --variabili
data NotedVal a           --valori: letterali e data constructor
data NotedMatchExpr a     --espressioni per il pattern match
data NotedExpr a          --expressioni
    \end{lstlisting}
    \item operazioni che riguardano la manipolazione dei tipi quali unificazione, test di specificità, specializzazione,
    instanziazione, generalizzazione. Inoltre, vi sono le funzioni e le strutture dati per gestire il dispatch statico.
\end{enumerate}
Nonostante la presenza di token tipati, non esiste una corrispondente versione tipata dell'AST con un unico entry point,
bensì le informazioni che riguardano un programma vengono memorizzate in "tabelle" (cfr. modulo
\texttt{Compiler.Types.Tables}):
\begin{lstlisting}
newtype TypesTable a          --tabella dei "modelli" di tipi
newtype DataConsTable a       --tabella dei data constructor
newtype ConstraintsTable a    --tabella dei "modelli" di constraints
newtype InstsTable a          --tabella dei bindings delle istanze
newtype PropMethodsTable a    --tabella dei metodi di proprieta'
newtype ImplTable a           --tabella delle istanze
data    TypedProgram a        --tabella dei bindings tipati
\end{lstlisting}
Vedremo nel dettaglio ogni tabella nelle descrizioni delle varie fasi del compilatore. Tuttavia, è necessaria una nota
su \texttt{TypesTable} e \texttt{ConstraintsTable}. Come si legge dai commenti, esse sono tabelle per memorizzare dei
"modelli". Tali modelli sono necessari alla costruzione dei tipi e dei predicati all'interno di un programma. Ad esempio,
date le seguenti definizioni in langgg:
\begin{lstlisting}
type Box a = Boxing a
property Stateful m =
    val getState : m a -> a
;;
\end{lstlisting}
Verranno creati dei token (presenti in \texttt{Compiler.Ast.Typed}) dei tipi:
\begin{lstlisting}
data LangNewType a            --type constructor
data LangNewConstraint a      --constraint constructor
\end{lstlisting}
che rappresenteranno rispettivamente il modello per tipi \texttt{Box} e il modello per constraints \texttt{Stateful} e che
verranno memorizzati nelle suddette tabelle.

Sempre nel modulo \texttt{Compiler.Types.Tables}, viene definito anche il cosiddetto "binding tipato":
\begin{lstlisting}
type BindingSingleton a = (NotedVar a, [NotedVar a], NotedExpr a)
data TypedBinding a =
      TyNonRec (BindingSingleton a)
    | TyRec [BindingSingleton a]
\end{lstlisting}
Osservando l'implementazione di \texttt{TypedBinding}, si nota come esistano due tipi di binding. Il primo è per i binding
non ricorsivi, mentre il secondo è per i binding che sono mutualmente ricorsivi fra loro (cfr. type-inference).

\subsubsection{Confronto con GHC}
Come è stato detto precedentemente, l'approccio del compilatore è quello di costruire tabelle man mano che le informazioni
vengono inferite dall'AST. GHC (the Glasgow Haskell Compiler) utilizza un approccio differente, in quanto non utilizza
alcuna "symbol table", bensì ogni token tipato (di GHC) nella compilazione di un programma Haskell da parte di GHC può
textit{puntare} ad altri token tipati [5]. Si crea così un grafo di strutture dati tipate. Ad esempio, GHC, per gestire
le entità di type constructor e data constructor, utilizza rispettivamente i token \texttt{TyCon} e \texttt{DataCon} (si
ricordi che GHC è scritto in Haskell):
\begin{lstlisting}
data TyCon
data DataCon
\end{lstlisting}
Ogni token di tipo \texttt{TyCon} punterà a una lista di \texttt{DataCon} che, a loro volta, conterranno la referenza
al loro costruttore di tipo. Come puntualizza Edward Y. Zang nell'introduzione dell'articolo [6],
uno svantaggio di questo approccio è che il grafo è immutabile e quindi, per poter
aggiornare i nodi del grafo è necessario ricostruire il grafo da zero. Tuttavia, questo problema è mitigato, in quanto
gli aggiornamenti del grafo sono parecchio rari, inoltre, man mano che GHC ottiene informazioni dal programma Haskell,
accrescerà il grafo senza aggiornare i nodi preesistenti; in questo modo, non vi è alcuna necessità di costruire il
grafo da zero.

\subsection{Il sistema di tipi}
In questo paragrafo, verrà presentato il sistema di tipi di langgg. Come è stato già menzionato in precedenza, il
linguaggio supporta il polimorfismo ad hoc e il polimorfismo parametrico; quest'ultimo viene implementato attraverso
il concetto di variabile di tipo, la quale può essere considerata come un "placeholder" per i tipi.

\subsubsection{Mono-tipo}
Di seguito, viene definito il concetto di \textit{mono-tipo}:
\[ MT \; := \; \alpha \; | \; T \; | \; MT \; MT \; | \; MT \mapsto MT \]
dove $ \alpha $ è una variabile di tipo e $ T $ è un costruttore di tipo. Come si può dedurre dalla definizione stessa,
non si deve confondere
il concetto di mono-tipo con quello di tipo \textit{monomorfo}, infatti i mono-tipi, a differenza dei tipi monomorfi,
ammettono le variabili di tipo. L'ultimo caso è il tipo \textit{funzione}; nella sezione sull'inferenza di tipo verrà
mostrato il motivo per il quale è fondamentale garantire la presenza del tipo funzione all'interno del type-system.
Nel compilatore, la definizione di mono-tipo si trova nel modulo \texttt{Compiler.Ast.Typed}:
\begin{lstlisting}
data LangHigherType a =
      LTy (LangType a)
    | HApp [LangHigherType a] a
\end{lstlisting}
dove \texttt{LangType} rappresenta tutti i tipi che possono essere definiti in langgg. Si noti come vi è un secondo
caso (\texttt{HApp}), il quale rappresenta il tipo funzione. Il costruttore \texttt{HApp} prende in input una lista
di mono-tipi, tuttavia il tipo funzione può avere al massimo due argomenti, perciò il modulo \texttt{Compiler.Ast.Typed}
si occupa internamente di rifiutare qualsiasi valore con costruttore \texttt{HApp} che abbia più di due argomenti.
La causa per la quale non vi è un numero fissato di argomenti è la presenza delle funzioni di tipo, infatti,
in questo modo, è possibile esprimere senza difficoltà, all'interno del compilatore, tipi come:
\begin{itemize}
\item \texttt{(->) a}
\item \texttt{(->)}
\end{itemize}

\subsubsection{Tipi higher-kinded}
langgg permette all'utente di utilizzare \textit{funzioni di tipo} (o \textit{costruttori di tipo}). A questo scopo,
viene introdotta la nozione di \textit{kind}, il quale rappresenta un'informazione aggiuntiva per i tipi. Informalmente,
dato un type-system \textit{TS}, un kind-system \textit{KS} si può vedere come un type-system di livello "superiore"
a \textit{TS}. Ora diamo una definizione più precisa di kind:
\[ K \; := \; \kappa \; | \; * \; | \; K \mapsto K \]
dove $ \kappa $ è una variabile di kind e $ * $ è la costante primitiva di kind (detta anche "tipo"), il quale
rappresenta tutti quei tipi che non hanno bisogno di parametri di tipi. Ecco alcuni esempi:
\begin{itemize}
    \item $ * \mapsto * $ è il kind delle funzioni di tipo unarie;
    \item $ (* \mapsto *) \mapsto * \mapsto * $ è il kind delle funzioni di tipo binarie che prendono in input una
    funzione di tipo unaria e un tipo e ritornano un altro tipo.
    \item $ \kappa_1 \mapsto \kappa_2 $ è il kind delle funzioni unarie che prendono in input una funzione di tipo
    di kind $ \kappa_1 $ e ritorna un'altra funzione di tipo di kind $ \kappa_2 $.
\end{itemize}
Data la presenza di tipi \textit{higher-kinded} all'interno di langgg, è doveroso fare un'ulteriore precisazione che
riguarda i mono-tipi: alla definizione di mono-tipo deve essere aggiunta la condizione sulla correttezza dei kind.
Ad esempio, dato il tipo:
\[ t_1 \mapsto t_2 \]
sapendo che il kind del costruttore di tipo funzione è $ * \mapsto * \mapsto * $, è necessario, affinché il suddetto
kind venga rispettato, che il kind di $ t_1 $ e $ t_2 $ sia $ * $.
%TODO: definizione di kind nel codice

\subsubsection{Subtyping: predicati e tipi qualificati}
La nozione di mono-tipo ammette le variabili di tipo, le quali fungono da placeholder per qualsiasi tipo dello stesso
kind della variabile. Tuttavia, solamente con la nozione di mono-tipo non è possibile fare asserzioni sulle variabili
di tipi, se non, appunto, che sono placeholder adatti a qualsiasi tipo. langgg supporta anche una nozione di sottotipo.
Prendiamo, ad esempio, la seguente variabile di tipo:
\[ \alpha : * \]
la notazione $ : * $ serve, in questo caso, per rendere esplicito il kind della variabile. $ \alpha $ è un placeholder
adatto a tipi quali, ad esempio, \texttt{Int}, \texttt{List b} oppure \texttt{List Char} poiché hanno tutti kind $ * $.
Potrebbe essere "comodo" fare asserzioni su $ \alpha $, ad esempio, si può asserire che $ \alpha $ è un placeholder
valido per tutti quei tipi $ S $ che sono sottotipi di un certo tipo $ T $. Una definizione lasca di sottotipo è la
seguente: se $ S $ è sottotipo di $ T $ (scriviamo $ S \leq T $), allora ogni termine di $ S $ può essere utilizzato
in maniera \textit{safe} in ogni \textit{contesto} in cui un termine di $ T $ è richiesto, dove le definizioni di
\textit{safe} e \textit{contesto} sono dipendenti dal formalismo.
Aggiungiamo una notazione per descrivere questa nozione:
\[ \alpha \leq T . \; \alpha \]
Possiamo quindi "restringere" i possibili tipi adatti a "riempire" il placeholder rappresentato da $ \alpha $. Più in
generale, possiamo considerare $ \alpha \leq T $ come un predicato $ P $ su $ \alpha $. Utilizzeremo, quindi, la seguente
notazione:
\[ P(\alpha) \Rightarrow \alpha \]
Ora abbiamo una sintassi per descrivere \textit{predicati} o \textit{constraint} sulle variabili di tipo. Tale
comportamento si può estendere a qualsiasi forma di tipo, non solo alle variabili di tipo, ma per farlo è necessario
prima definire la sintassi dei predicati. In langgg, un predicato o constraint ha la seguente forma:
\[ C := P \; MT_1 \; ... \; MT_n \]
dove $ P $ è il nome di una proprietà (cfr. polimorfismo ad hoc). Ora possiamo quindi definire un'estensione dei
mono-tipi, in modo che su questi ultimi si possano aggiungere delle ipotesi. Per una definizione più generale possibile,
ammettiamo che su un mono-tipo si possa applicare un numero arbitrario di predicati:
\[ QT := MT \; | \; C \Rightarrow QT \]
Questa appena data è la nozione di \textit{tipo qualificato}. La definizione si trova nel modulo
\texttt{Compiler.Ast.Typed}:
\begin{lstlisting}
data LangQualType a = Qual [LangSpecConstraint a] (LangHigherType a)
\end{lstlisting}

\subsubsection{Schemi di tipi}
Finora abbiamo trattato mono-tipi e tipi qualificati, tuttavia, la sola presenza delle variabili di tipo non è sufficiente
a costruire tipi "polimorfi". Si consideri il seguente esempio:
\[ map : (\alpha \mapsto \beta) \mapsto List \; \alpha \mapsto List \; \beta \]
In questo caso, il tipo della funzione $ map $ non è polimorfo, in quanto le variabili di tipo $ \alpha $ e $ \beta $
rappresentano un tipo fissato non ancora conosciuto. Per ottenere il polimorfismo, è necessario introdurre
dei quantificatori, ad esempio, possiamo rifinire il tipo di $ map $ nel modo seguente:
\[ map : \forall \alpha, \beta . \; (\alpha \mapsto \beta) \mapsto List \; \alpha \mapsto List \; \beta \]
A differenza di prima, in cui $ map $ aveva un tipo prefissato, qui può avere molteplici tipi. Ora diamo la definizione
di \textit{schema di tipo} o \textit{poli-tipo} in langgg:
\[ PT := QT \; | \; \forall \alpha. \; PT \]
Questa definizione lascia spazio alla presenza di \textit{variabili libere}, in quanto non necessariamente tutte le
variabili di tipo che compaiono in un tipo qualificato sono legate a un quantificatore. Le variabili libere vengono
trattate come costanti. Si noti come i quantificatori possono apparire solamente alla testa di un tipo, ad esempio, il
seguente tipo non è accettato in langgg:
\[ \forall \alpha . \; (\forall \alpha . \; \alpha \mapsto \alpha) \mapsto \alpha \]
%TODO: System F
La definizione di schema di tipo in langgg si trova nel modulo \texttt{Compiler.Ast.Typed}:
\begin{lstlisting}
data LangTypeScheme a = Forall [LangVarType a] (LangQualType a)
\end{lstlisting}
La politica sulla sintassi degli schemi di tipi di langgg è omettere il quantificatore $ \forall $. Per questo, ogni qual
volta vi è un costrutto di type-hinting (firme comprese), il tipo viene considerato come uno schema di tipo in cui tutte
le variabili di tipo che compaiono vengono legate a un quantificatore, ad esempio:
\begin{lstlisting}
val map : (a -> b) -> List a -> List b
\end{lstlisting}
in questo caso la funzione \texttt{map} avrà il seguente tipo:
\[ map : \forall \alpha, \beta . \; (\alpha \mapsto \beta) \mapsto List \; \alpha \mapsto List \; \beta \]

\subsection{Polimorfismo ad hoc}
langgg supporta il polimorfismo ad hoc esponendo costrutti chiamati \textit{proprietà}, le quali sono concettualmente
molto simili alle \textit{type classes} di Haskell. Ecco un esempio di definizione di proprietà in langgg:
\begin{lstlisting}
property Eq a =
    val (==) : a -> a -> Bool
    val (/=) : a -> a -> Bool
;;
\end{lstlisting}
Questo pezzo di codice produce idealmente due token corrispondenti ai metodi \texttt{(==)} e \texttt{(/=)},
i quali possono essere istanziati attraverso il meccanismo delle istanze che verrà presentato prossimamente. I token
appena costruiti avranno le seguenti firme:
\begin{lstlisting}
val (==) : Eq a => a -> a -> Bool
val (/=) : Eq a => a -> a -> Bool
\end{lstlisting}
Si noti come le firme effettive non siano le stesse di quelle date dall'utente, le quali risultano incomplete.
All'inizio della dicitura dei tipi effettivi, si può notare un \textit{constraint} o \textit{predicato} seguito da una
freccia, la quale è intesa come implicazione. I tipi dei metodi di proprietà avranno quindi la forma:
    \[ Pred(\overline{\alpha}) \Rightarrow ty(\overline{\alpha}) \]
dove \textit{Pred} è un predicato e \textit{ty} è un tipo qualunque sulle variabili $ \overline{\alpha} $.
Il polimorfismo ad hoc viene, dunque, supportato attraverso i predicati, i quali rappresentano delle ipotesi aggiuntive
sui tipi. L'istanziazione di una proprietà consiste nel dichiarare dei tipi che fungeranno da "caso particolare" per i
metodi di proprietà (i "modelli"), ad esempio, riprendendo la proprietà \texttt{Eq} del precedente pezzo di codice,
in langgg possiamo definire un'istanza del tipo:
\begin{lstlisting}
instance Eq Char where
    <implementazioni>
;;
\end{lstlisting}
I dettagli implementativi al momento sono omessi. In ogni caso, i metodi di istanza avranno le seguenti firme:
\begin{lstlisting}
val (==) : Char -> Char -> Bool
val (/=) : Char -> Char -> Bool
\end{lstlisting}
Si può notare come il predicato su \texttt{Eq} non esiste più.

\subsubsection{Estensioni del polimorfismo ad hoc}
Il meccanismo di polimorfismo ad hoc precedentemente presentato incontra numerose estensioni in langgg, alcune delle
quali impongono condizioni aggiuntive sul programma.

\subparagraph{Numero arbitrario di argomenti delle proprietà}
Nell'esempio con \texttt{Eq}, la proprietà possedeva soltanto un argomento, tuttavia, è possibile definire proprietà
con un numero arbitrario (ma fissato alla definizione) di argomenti ad esempio:
\begin{lstlisting}
property Stream s t =
    val new : t -> s t
    val yield : t -> s t -> s t
    val consume : s t -> (s t, t)
;;
\end{lstlisting}
Si noti che \texttt{Stream} ha 2 argomenti.

\subparagraph{Constraints sulle proprietà}
\`E possibile definire in langgg una proprietà della forma:
\begin{lstlisting}
property C1 a Char => C2 a =
    <metodi>
;;
\end{lstlisting}
Questo tipo di definizione consiste nell'aggiungere il predicato \texttt{C1 a} alla proprietà \texttt{C2 a}.
Semanticamente, questo impone la seguente condizione sul programma:
    \[ \forall type . \; \exists inst(C2, type) \Longrightarrow \exists inst(C1, type, Char) \]
dove $ inst(C, \overline{t}) $ è, banalmente, l'instanza con nome di proprietà $ C $ e tipi $ \overline{t} $. \`E
possibile aggiungere più di un predicato alla stessa proprietà.

\subparagraph{Polimorfismo higher-kinded}
Riprendiamo il precedente esempio con \texttt{Stream}:
\begin{lstlisting}
property Stream s t =
    val new : t -> s t
    val yield : t -> s t -> s t
    val consume : s t -> (s t, t)
;;
\end{lstlisting}
Gli argomenti di una proprietà sono sempre variabili di tipo. Come è già stato menzionato in precedenza, langgg supporta
tipi di kind arbitrari; gli argomenti delle proprietà non fanno eccezione da questo punto di vista, infatti, nell'esempio
si può notare come la variabile \textit{s} abbia kind (utilizzando la rappresentazione dei kind di Haskell):
    \[ * \mapsto * \]
mentre la variabile \textit{t} ha kind:
   \[ * \]

\subparagraph{Argomenti arbitrari delle istanze}
Gli argomenti di un'istanza possono essere tipi di forma arbitraria, ad esempio:
\begin{lstlisting}
property C x y =
    <metodi>
;;

instance C a (Tuple3 a (T b) (m b)) =
    <implementazioni>
;;
\end{lstlisting}
Confrontando il precedente codice langgg con il seguente codice Haskell che può considerarsi quanto meno concettualmente
equivalente:
\begin{lstlisting}
{-# LANGUAGE MultiParamTypeClasses #-}

class C x y where
    <metodi>

instance C a (a, T b, m b) where
    <implementazioni>
\end{lstlisting}
si ha che, compilando questo programma Haskell soltanto con l'estensione all'inizio del codice, si incorrerà nel
seguente messaggio d'errore da parte del compilatore:
\begin{lstlisting}
Illegal instance declaration for 'C a (a, T b, m b)'
(All instance types must be of the form (T a1 ... an)
where a1 ... an are *distinct type variables*,
and each type variable appears at most once in the instance head.
Use FlexibleInstances if you want to disable this.)
\end{lstlisting}
Come suggerisce l'ultima riga del messaggio d'errore, per definire un'istanza del genere in un programma Haskell è
necessario utilizzare l'estensione \texttt{FlexibleInstances} [7]. In langgg, a differenza di Haskell, quel tipo di instanza
è accettato di default. Il seguente vincolo sulla forma dei tipi riportato nel messaggio d'errore viene dunque rilassato:
    \[ TyCon(\overline{\alpha}) \]
dove $ \overline{\alpha} $ sono variabili di tipo distinte e $ TyCon $ è un costruttore di tipo. In seguito, verrà
mostrato quali vincoli che riguardano i constraints e le istanze possono essere rilassati e con quali conseguenze.

\subparagraph{Constraints sulle istanze}
L'utente ha anche la facoltà di definire istanze con uno o più predicati, ad esempio:
\begin{lstlisting}
instance Monad m => Stream m String =
    <implementazioni>
;;
\end{lstlisting}
questo tipo di definizione genererà metodi di istanza con le seguenti firme:
\begin{lstlisting}
val new : Monad m => String -> m String
val yield : Monad m => String -> m String -> m String
val consume : Monad m => m String -> (m String, String)
\end{lstlisting}
Il constraint sull'istanza viene quindi applicato al tipo dei metodi di istanza.

\subsubsection{Condizioni sui constraint}
I constraints rappresentano un modo per "restringere" i possibili tipi che possono istanziare una o più variabili di
tipo. I tipi nelle firme delle variabili (nonché i type-hinting) possono possedere zero o più constraint; lo stesso
vale, come viene mostrato nei paragrafi precedenti, anche per le proprietà e per le istanze. Esistono, però, dei
vincoli sulla forma dei constraint. Come viene mostrato in [8] e [9], esistono condizioni (di Paterson) sufficienti
affinché l'algoritmo di risoluzione delle istanze di Haskell termini. Prima di presentarle, diamo alcune notazioni:
\newline Dato un costrutto $ K $ in cui compaiono dei constraints $ C \Rightarrow D $, definiamo
\begin{itemize}
    \item $ C $ come \textit{Contesto} del costrutto $ K $;
    \item $ H $ come \textit{Testa} del costrutto $ K $.
\end{itemize}
Ora presentiamo le condizioni di Paterson:
\begin{itemize}
    \item il contesto \textit{C} di una dichiarazione di type-class può menzionare solamente variabili di tipo e
    le variabili di tipo sono distinte in ogni singolo constraint in \textit{C};
    \item Per ogni dichiarazione di istanza $ C \Rightarrow TyCl \; t_1 ... t_n $, nessuna variabile di tipo ha
    più occorrenze nel contesto $ C $ rispetto alla testa $ TyCl \; t_1 ... t_n $.
    \item Per ogni dichiarazione di istanza $ C \Rightarrow TyCl \; t_1 ... t_n $, ogni constraint nel contesto
    $ C $ ha meno costruttori e variabili di tipo (presi insieme e contando le ripetizioni) rispetto alla testa
    $ TyCl \; t_1 ... t_n $.
    \item Per ogni due dichiarazioni di istanze $ C \Rightarrow TyCl \; t_1 ... t_n $,
    $ C' \Rightarrow TyCl \; t_1' ... t_n' $, non deve esistere una sostituzione $ \varphi $ tale che:
    $ \varphi(t_1) = \varphi(t_1') $, ..., $ \varphi(t_n) = \varphi(t_n') $.
\end{itemize}
Informalmente, l'obiettivo è avere sempre dei contesti più "piccoli" rispetto alle teste. La politica di langgg è
simile e applica i seguenti vincoli:
\begin{enumerate}
    \item Per ogni constraint $ c $, $ c $ deve contenere almeno una variabile di tipo, ovvero:
    \[ \forall \; constraint =: c.\; \exists \; tyvar =: v.\; v \in c \]
    \item Per ogni istanza $ ctx \Rightarrow h $, il numero di occorrenze di ogni singola variabile $ v $ nel contesto
    $ ctx $ deve essere minore o uguale rispetto al numero di occorrenze di $ v $ nella testa $ h $, ovvero:
    \[ \forall \; instance =: (ctx \Rightarrow h).\; \forall \; tyvar =: v.\; v \in instance
    \Longrightarrow occ(v, ctx) \leq occ(v, h) \]
    \item Per ogni istanza $ ctx \Rightarrow h $, le variabili di tipo di $ ctx $ devono essere innestate in meno
    costruttori di tipo rispetto alle variabili di tipo di $ h $ (contando le variabili tutte insieme), ovvero: \newline
    \[ \forall \; instance =: (ctx \Rightarrow h).\; countWrapVars(ctx) < countWrapVars(h) \]
\end{enumerate}
dove $ occ(v, k) $ è la funzione che conta le occorrenze della variabile di tipo $ v $ nel costrutto $ k $ e
$ countWrapVars(k) $ è la funzione che conta in quanti costruttori di tipo nel costrutto $ k $ sono innestate le
variabili di tipo (sommando il risultato per tutte le variabili di tipo incontrate). Il codice che implementa questi
controlli risiede nel modulo \texttt{Compiler.Constraints.Check}.

\subsection{Kind-inference}
%TODO

\subsection{Data constructors}
Una delle tabelle di simboli che appare nel modulo \texttt{Compiler.Types.Table} è \texttt{DataConsTable}. In essa
vengono salvati i \textit{data constructor} associati ai loro tipi. I costruttori - che nell'AST vengono rappresentati
dal token \texttt{ADTConstructor} - vengono trasformati nel token \texttt{NotedVal} presente nel modulo
\texttt{Compiler.Ast.Typed} che consiste nella seguente coppia:
\[ < dataConRep, type > \]
dove $ dataConRep $ è la rappresentazione sotto forma di stringa del data constructor, mentre $ ty $ è il tipo del
costruttore. Per quanto riguarda il tipo del costruttore, prendiamo in considerazione il seguente esempio di codice
langgg:
\begin{lstlisting}
type Foo x y = Bar Int (M x) y
\end{lstlisting}
In questa definizione di tipo di dato algebrico, vi è un solo costruttore: \texttt{Bar}. Il suo tipo è il seguente:
\[ \forall x, y. \; Int \mapsto M \; x \mapsto y \mapsto Foo \; x \; y \]
Il tipo di ritorno è sempre dato dalla definizione del tipo. Il modulo che si occupa di trasformare i token
\texttt{ADTConstructor} in \texttt{NotedVal} e aggiungerli nella tabella \texttt{DataConsTable} è
\texttt{Compiler.Types.Builder.Cons}.

\subsection{Constraint constructors}
Dopo il check sui constraints e la generazione di data constructors, il compilatore si occupa di generare i cosiddetti
"\textit{constraint constructors}", ovvero token che fungono da modelli per la costruzione di predicati. Il modulo
che li genera è \texttt{Compiler.Types.Tables}; esso prende in input i token dell'AST che rappresentano le proprietà
(\texttt{Interface}) e da essi costruisce i token tipati \texttt{LangNewConstraint} e li inserisce nella tabella
\texttt{ConstraintsTable}. \`E compito di questo modulo controllare che le classi non formino cicli tra loro, ad
esempio, il seguente programma viene rifiutato dal compilatore:
\begin{lstlisting}
property Bar (M a) Int => Foo a =
    <metodi>
;;

property Foo (K x Char) => Bar x y =
    <metodi>
;;
\end{lstlisting}
Si noti come i vincoli sui constraints vengano tutti rispettati.

\subsection{Costruzione delle istanze}
Nel modulo \texttt{Compiler.Types.Builder.Instances} vengono create le seguenti 3 tabelle:
\begin{itemize}
    \item \texttt{InstsTable}, ovvero la tabella che contiene i bindings (sotto forma di token dell'AST) delle istanze;
    \item \texttt{PropMethodsTable}, ovvero la tabella che contiene i metodi delle proprietà sotto forma di token
    tipati;
    \item \texttt{ImplTable}, ovvero la tabella che contiene i constraints che derivano dalle istanze definite
    dall'utente;
\end{itemize}
Per quanto riguarda l'ultima tabella, data la definizione di un'istanza:
\begin{lstlisting}
instance Eq Char =
    <implementazioni>
;;
\end{lstlisting}
la testa \texttt{Eq Char} ha la forma di un constraint, nonostante non rispetti uno dei vincoli sui constraints (un
constraint deve avere almeno una variabile di tipo), infatti l'istanza viene salvata sotto forma di constraint
(\texttt{LangSpecConstraint}).
Le tre tabelle vengono create in un unico modulo per una questione di efficienza (i token delle istanze vengono visitati
una sola volta). Inoltre, in questo
modulo viene effettuato il controllo del vincolo sull'esistenza dei predicati delle proprietà (cfr. paragrafo "constraints
delle proprietà" in "Estensioni del polimorfismo ad hoc"). Prima di inserire i bindings delle istanze nella
tabella \texttt{InstsTable}, viene eseguita una fase di desugaring su di essi. Il problema nasce dal fatto che, data
una proprietà, può esistere un numero arbitrario di istanze e con esse, un numero arbitrario di metodi con lo stesso
nome, perciò è necessario identificare univocamente i metodi di ogni singoli istanza. Il modulo
\texttt{Compiler.Desugar.Names} si occupa di, dato il nome di una variabile e una sequenza di constraints (gli argomenti
di un'istanza), creare un identificatore univoco che non può essere uguale a nessun altro identificatore nel programma.

\subsection{Preparazione alla type-inference}
Prima di effettuare la type-inference è necessario fare alcune considerazioni ed effettuare alcune computazioni.
Innazitutto, il type-system di riferimento è \textit{Hindley-Milner} (o Damas-Hindley-Milner, in seguito lo indicheremo con HM)
con alcune estensioni che riguardano il costrutto del pattern matching, l'inferenza di definizioni ricorsive e la
risoluzione delle istanze. Il modulo che si occupa della preparazione alla type-inference è \texttt{Compiler.Types.Prepare}
Introdurremo il type-system in modo preciso prossimamente (cfr. Type-inference), tuttavia, ora presentiamo alcune
caratteristiche del type-system che è bene conoscere come premessa alla preparazione della type-inference.
Innanzitutto, HM viene descritto formalmente da un insieme di \textit{regole} le quali si occupano di "tipare"
espressioni di un formalismo fissato: una versione del lambda-calcolo estesa con un costrutto di espressioni "let..in".
Una delle regole è quella sull'inferenza del tipo di un simbolo (la regola la chiameremo chiamiamo \textbf{Var})
la quale, informalmente, sostiene che: data l'ipotesi di un simbolo $ x $ con schema di tipo $ \sigma $ nel contesto di
un ambiente di tipizzazione $ \Gamma $ e $ \tau $ l'istanziazione del tipo $ \sigma $, si conclude che il simbolo
$ x $ ha tipo $ \tau $.
Un'altra regola utile è quella
sull'inferenza delle definizioni mutualmente ricorsive. In particolare, essa sostiene che, l'inferenza di definizioni
mutualmente ricorsive avviene in "gruppo", ovvero un insieme $ {f_1, ..., f_n} $ di simboli mutualmente ricorsivi
tra loro vengono considerati nel loro insieme e non singolarmente (regola \textbf{Rec}).
Queste regole serviranno come premessa ad alcune fasi nella preparazione della type inference.

\subsubsection{Bindings delle istanze}
\`E bene notare come in Core non esista un costrutto particolare per i bindings delle istanze, inoltre, il
costrutto di GHC che rappresenta le istanze (\texttt{ClsInst}) non porta con sè informazioni che riguardano i
bindings [10].
Perciò, è in un qualche modo necessario gestire i bindings delle istanze. La politica del compilatore è quella di
aggiungerli nell'insieme di bindings da dare in input all'algoritmo di type-inference. La presenza di bindings con lo
stesso identificatore è stata già risolta (cfr. Costruzione delle istanze).

\subsubsection{Simboli innestati univoci}
Prima della type-inference, vengono visitate tutte le espressioni dei bindings e vengono creati nuovi identificatori
per ogni definizione innestata di variabile (costrutto \texttt{let..in}). I nuovi identificatori sono resi univoci in
tutto il programma. Il modulo che crea e garantisce che i nuovi identificatori sono univoci è
\texttt{Compiler.Desugar.Names}. La proprietà di unicità degli identificatori innestati è molto importante, vedremo in
seguito il motivo (cfr. type-inference).

\subsubsection{Clusters di definizioni mutualmente ricorsive}
Come è stato già menzionato precedentemente, le definizioni mutualmente ricorsive devono essere considerate come insiemi
e non singolarmente. Perciò è necessario distinguere due tipi di bindings, quelli mutualmente ricorsivi e i restanti:
\begin{lstlisting}
data RawBinding =
      RawNonRec (Raw.SDUnion With.ProgState)
    | RawRec [Raw.SDUnion With.ProgState]
\end{lstlisting}
La precedente definizione è nel modulo \texttt{Compiler.Types.Prepare.Lib} e divide i bindings dell'AST in bindings
non ricorsivi e bindings mutualmente ricorsivi. Rimane, quindi, da dividere i bindings del programma. Prima di presentare
l'algoritmo, bisogna effettuare una precisazione molto importante. In precedenza, abbiamo aggiunto i bindings delle
istanze alla lista dei bindings del programma, cambiando, però, gli identificatori, rendendoli univoci all'interno del
programma. Per dividere riconoscere i bindings mutualmente ricorsivi è necessaria una funzione che calcoli le dipendenze
di una definizione. Nelle espressioni, in generale, possono essere menzionati i metodi delle proprietà, ma non possono,
in alcun modo, essere menzionati i metodi delle istanze. Inoltre, il tipo dei metodi delle proprietà è sempre noto a
priori e non è possibile, prima della type-inference, inferire le istanze (cfr. static dispatch) giuste dei metodi.
Nel calcolo delle dipendenze, i metodi di proprietà possono, quindi, essere esclusi. La funzione \textit{depsOf}, la quale
prende in input un binding \texttt{b} dell'AST e la tabella \texttt{PropMethodsTable}, calcolerà le dipendenze di
\texttt{b}, escludendo le dipendenze che provengono dalla tabella dei metodi di proprietà. L'insieme dei bindings di
un programma può essere visto come un grafo orientato $ G $ in cui:
\begin{itemize}
    \item i nodi sono i bindings;
    \item gli archi sono le dipendenze di un binding.
\end{itemize}
Il problema di trovare i clusters di definizioni mutualmente ricorsive corrisponde a trovare le \textit{componenti
fortemente connesse} del grafo $ G $. Il modulo che implementa l'algoritmo è \texttt{Compiler.Types.Prepare.Recursion}
e utilizza la libreria \texttt{Data.Graph}.

\subsubsection{Sorting dei bindings}
A questo punto, abbiamo una lista di \texttt{RawBinding}. Possiamo fare la seguente osservazione: i bindings possono
essere visti come un grafo orientato aciclico $ G $, in cui, come prima:
\begin{itemize}
    \item i nodi sono i bindings;
    \item gli archi sono le dipendenze di un binding.
\end{itemize}
L'unica differenza è sull'aciclicità del grafo. Questa proprietà è garantita dal seguente fatto: se esistesse un ciclo
in $ G $, allora l'algoritmo di raggruppamento dei clusters l'avrebbe trovato e avrebbe creato un cluster di definizioni
mutualmente ricorsive tra loro. La regola di inferenza \textbf{Var} impone che si conosca sempre lo schema di tipo di
un simbolo, perciò, è necessario, prima di effettuare la type-inference, ordinare i bindings in base alle loro dipendenze.
L'ordinamento viene effettuato nel modulo \texttt{Compiler.Types.Prepare.Sort} e l'algoritmo utilizzato è un'estensione
dell'insertion-sort, dove, la nozione di ordinamento è data dalle dipendenze dei bindings, ovvero: \newline
Siano $ b $ e $ b' $ due bindings, si ha che:
\begin{itemize}
    \item $ b > b' $, se $ b' $ è una dipendenza diretta di $ b $ oppure esistono dei bindings $ c_1, ..., c_n $ tali che:
    \newline $ (b > c_1) \wedge (c_1 > c_2) \wedge ... \wedge (c_{n-1} > c_n) \wedge (c_n > b') $;
    \item $ b = b' $, se la componente di $ b $ in $ G $ non è raggiungibile da nessun nodo della componente $ b' $.
\end{itemize}
la proprietà di transitività di questa nozione di ordinamento è garantita dall'assenza di cicli all'interno del grafo.
Di seguito vi è l'algoritmo di sorting di una singola componente del grafo:
\begin{lstlisting}
sortComponent(bindings, remaining, component):
    match bindings, remaining with
        [], [] -> component
        [], (_ : _) -> sortComponent remaining [] component
        (b : t), _ ->
            let (inserted, component') = tryInsert b component in
                if inserted
                then sortComponent t remaining component'
                else sortComponent t (addTail b remaining) component 
\end{lstlisting}
L'algoritmo prende in input i bindings di una componente, i bindings rimanenti e la componente già ordinata. Ora
presentiamo l'algoritmo di inserzione di un binding in una componente già ordinata:
\begin{lstlisting}
tryInsert(binding, component):
    match component with
        [] -> [component]
        (b : t) ->
            if b in depsOf(binding)
            then tryInsert binding t
            else if binding in depsOf(b)
            then (True, binding : component)
            else (False, component)
\end{lstlisting}
Ora abbiamo implementato una versione alternativa dell'insertion sort in cui gli inserimenti vengono effettuati
solamente se si è a conoscenza che il binding da inserire fa parte delle dipendenze dirette di un altro binding già
inserito nella componente. Inoltre, se non vi sono abbastanza informazioni per inserire un binding in una componente,
il suo inserimento viene "rimandato" (viene inserito nei bindings rimanenti) e verrà effettuato in un'iterazione
successiva. Il codice si trova nel modulo \texttt{Compiler.Types.Prepare.Sort}.

Dopo l'ordinamento dei bindings, è garantito che, ogni qual volta verrà inferito un binding, è garantito che la premessa
della regola \textbf{Var} sia vera.

\subsection{Type-inference}
langgg permette all'utente di indicare o non indicare il tipo di una variabile. Nel caso non venga indicato, il
compilatore dovrà inferire il tipo della variabile definita, quindi dovrà fare una "scelta". Per farlo, dovrà prima
inferire il tipo dell'espressione legata alla variabile, ad esempio:
\begin{lstlisting}
type Maybe a = Nothing | Just a
let x = Nothing
\end{lstlisting}
Si può affermare che l'espressione legata alla variabile $ x $ abbia tipo $ Maybe \alpha $. Ora, il compilatore
deve scegliere un tipo da sostituire alla variabile di tipo $ \alpha $. Se la scelta fosse arbitraria, ad esempio
$ Int $, l'utilizzo di $ x $ sarebbe limitato solo a un tipo ovvero $ Maybe Int $. Un'altra possibile soluzione
potrebbe essere associare a $ x $ il tipo $ Maybe a $. Tuttavia, anche questa scelta risulterebbe limitante in quanto,
come è stato già esposto nella sezione sul type-system (cfr. Schemi di tipi), la variabile di tipo $ \alpha $
denoterebbe un tipo fissato non ancora conosciuto. L'introduzione di uno schema di tipo rappresenta una scelta
"più generale":
\[ x : \forall \alpha. \; Maybe \; \alpha \]
In questo caso, $ x $ può avere molteplici tipi.

\subsubsection{Damas-Hindley-Milner}
Come è stato già menzionato precedentemente, il sistema di tipi di langgg si basa sul type-system di Damas-Hindley-Milner.
L'algoritmo di inferenza su cui si basa inferisce il tipo più \textit{generale} possibile.
%TODO

\subsubsection{Regole di inferenza}
Come è stato già anticipato, HM viene presentato sotto forma di \textit{regole}, le quali hanno la seguente forma:
\newline
\[ \infer[\textbf{Regola}]{Conclusione}{Premesse} \]
dove le premesse sono un insieme di \textit{giudizi} e \textit{predicati} e la conclusione è un \textit{giudizio}. Un
\textit{giudizio} è un'affermazione sul tipo di un simbolo, ad esempio:
\[ x : \sigma \]
afferma che il simbolo $ x $ tipo $ \tau $. Ora verranno elencate le regole di inferenza:

\paragraph{Inferenza di variabile}
Prima di presentare di la regola d'inferenza delle variabili è necessario due ulteriori regole. La prima è la
regola di specializzazione e introduce una nozione d'ordine parziale tra tipi:
\[ \infer[\textbf{Spec}]{\forall \alpha_1 ... \forall \alpha_n. \; \tau \sqsubseteq \forall \beta_1 ... \beta_m. \; \tau'}{\tau' = \{ \alpha_i \mapsto \tau_i \}\tau & \beta_i \notin free(\forall \alpha_1 ... \forall \alpha_n . \; \tau)} \]
Questa regola sostiene che se esiste una sostituzione $ S = \{ \alpha_i \mapsto \tau_i \} $ tale che $ \tau' = S \tau $,
allora la versione "quantificata" dei mono-tipi $ \tau $ e $ \tau' $ rispetta la relazione d'ordine parziale
$ \sqsubseteq $. Nella premessa vi è un'ulteriore condizione che afferma che le variabili quantificate di $ \tau' $
non devono apparire come variabili libere in $ \forall \alpha_1 ... \alpha_n. \; \tau $; questo perché le variabili
non legate da un quantificatore (quindi libere) non devono essere sostituite, bensì devono essere trattate come costanti.
All'interno del codice, i token tipati che implementano la type-class \texttt{SpecType} in \texttt{Compiler.Ast.Typed}
permettono l'applicazione di una sostituzione al loro tipo.
La prossima regola rappresenta l'algoritmo di instanziazione:
\[ \infer[\textbf{Inst}]{\Gamma \vdash_W e : \tau}{\Gamma \vdash_W e : \sigma & \sigma \sqsubseteq \tau} \]
Questa regola è utile per istanziare uno schema di tipo in mono-tipo. \`E chiaro che è necessario tener conto delle
eventuali variabili libere nello schema di tipo $ \sigma $, ma queste vengono gestite dalla regola di specializzazione.
Ora, possiamo esporre la regola di inferenza di una variabile, la quale è stata già introdotta in precedenza, seppur
in maniera informale.
\[ \infer[\textbf{Var}]{\Gamma \vdash_W x : \tau, \; \emptyset}{x : \sigma \in \Gamma & \tau = inst(\sigma)} \]
\`E doveroso notare che nella conclusione, oltre al giudizio sul tipo della variabile, vi è un altro valore in "output",
ovvero le eventuali sostituzioni generate dall'inferenza dei costrutti coinvolti. In questo non vi è alcuna sostituzione.

\paragraph{Inferenza di applicazione}
La prossima regola serve per inferire l'applicazione di due espressioni:
\[ \infer[\textbf{App}]{\Gamma \vdash_W e_0 e_1 : S_2\tau', \; S_2S_1S_0}{\Gamma \vdash_W e_0 : \tau_0, \; S_0 & S_0\Gamma \vdash_W e_1 : \tau_1, \; S_1 & \tau' = newvar & S_2 = mgu(S_1\tau_0, \tau1 \mapsto \tau')} \]
Vi sono due nuovi operatori:
\begin{itemize}
    \item $ newvar $, il quale ritorna una nuova variabile di tipo $ \alpha $ tale che $ \alpha \notin free(\Gamma) $;
    \item $ mgu $, il quale rappresenta l'algoritmo di unificazione che verrà presentato dettagliatamente nel prossimo
    paragrafo. Tralasciando, quindi, i dettagli implementativi, tale operatore serve per trovare il tipo più generale.
    Come risultato, fornisce una sostituzione $ S_2 $, la quale viene successivamente applicata al mono-tipo $ \tau' $
    per ottenere il tipo di ritorno del costrutto di applicazione.
\end{itemize}

\paragraph{Unificazione}

\paragraph{Inferenza di lambda astrazione}
\[ \infer[\textbf{Abs}]{\Gamma \vdash_W \lambda x. e : S\tau \mapsto \tau', S}{\tau = newvar & \Gamma, \; x : \tau \vdash_W e : \tau', \; S} \]

\paragraph{Inferenza del costrutto "let..in"}
\[ \infer[\textbf{Let}]{\Gamma \vdash_W let x = e_0 in e_1 : \tau', \; S_1S_0}{\Gamma \vdash_W e_0 : \tau, \; S_0 & S_0\Gamma, x : \overline{S_0\Gamma}(\tau) \vdash_W e_1 : \tau', \; S_1} \]

\section*{Bibliografia}
\begin{enumerate}[label={[\arabic*]}]
    %[1]
    \item Amr Sabry - What is a purely functional language? - in: Journal of Functional Programming, Volume 8, Issue 1,
    January 1998, pp. 1 - 22
    %[2]
    \item Martin Sulzmann, Martin Odersky, Martin Wehr - Type Inference with Constrained Types - in: Theory and Practice
    of Object Systems · January 1999
    %[3]
    \item Stephen Diehl - Dive into GHC: Targeting Core - url: \url{https://www.stephendiehl.com/posts/ghc_03.html}
    %[4]
    \item libreria Parsec - url: \url{https://hackage.haskell.org/package/parsec}
    %[5]
    \item Data types for Haskell entities - url:
    \url{https://gitlab.haskell.org/ghc/ghc/-/wikis/commentary/compiler/entity-types}
    %[6]
    \item Edward Y. Zang - Backpack without symbol tables - in: May 11, 2016 - url:
    \url{http://web.mit.edu/~ezyang/Public/backpack-symbol-tables.pdf}
    %[7]
    \item Haskell Flexible Instances extension - url:
    \url{https://ghc.gitlab.haskell.org/ghc/doc/users_guide/exts/instances.html#extension-FlexibleInstances}
    %[8]
    \item Haskell instance resolution termination conditions - url:
    \url{https://ghc.gitlab.haskell.org/ghc/doc/users_guide/exts/instances.html#instance-termination-rules}
    %[9]
    \item Martin Sulzmann, Gregory J. Duck, Simon Peyton-Jones, Peter J. Stuckey - Understanding Functional Dependencies
    via Constraint Handling Rules - in: Journal of Functional Programming, Volume 17, Issue 1, January 2007, pp. 83 - 129
    %[10]
    \item Definizione di ClsInst in GHC - url: \url{https://hackage.haskell.org/package/ghc-8.10.7/docs/src/InstEnv.html#ClsInst}
\end{enumerate}

\end{document}
